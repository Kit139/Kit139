<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>您没有权限打开应用程序——更新到Big Sur？</title>
      <link href="2021/02/11/%E6%82%A8%E6%B2%A1%E6%9C%89%E6%9D%83%E9%99%90%E6%89%93%E5%BC%80%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E2%80%94%E2%80%94%E6%9B%B4%E6%96%B0%E5%88%B0Big%20Sur%EF%BC%9F/"/>
      <url>2021/02/11/%E6%82%A8%E6%B2%A1%E6%9C%89%E6%9D%83%E9%99%90%E6%89%93%E5%BC%80%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E2%80%94%E2%80%94%E6%9B%B4%E6%96%B0%E5%88%B0Big%20Sur%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="您没有权限打开应用程序——更新到Big-Sur？"><a href="#您没有权限打开应用程序——更新到Big-Sur？" class="headerlink" title="您没有权限打开应用程序——更新到Big Sur？"></a>您没有权限打开应用程序——更新到Big Sur？</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Mac更新到Big Sur打开pj软件——”您没有权限打开应用程序XXX，请联系您的电脑或者网络管理员以获得帮助。“</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/%E6%88%AA%E5%B1%8F2021-02-11%2018.31.17.png" alt="截屏2021-02-11 18.31.17"></p><p>那么如何解决呢？</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>苹果推出最新macOS Big Sur 时，建立了关于被PJ软件版权的一种版权保护的机制。</p><h2 id="解决方案（二选一）"><a href="#解决方案（二选一）" class="headerlink" title="解决方案（二选一）"></a>解决方案（二选一）</h2><h3 id="简单解决"><a href="#简单解决" class="headerlink" title="简单解决"></a>简单解决</h3><p>在出现损坏的 app 上右键，依次打开 “显示包内容-Contents-MacOS”，然后把该目录下的文件，拖到下述命令的后方执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod +x </span><br></pre></td></tr></table></figure><h3 id="利用第三方插件——upx-脱壳"><a href="#利用第三方插件——upx-脱壳" class="headerlink" title="利用第三方插件——upx 脱壳"></a>利用第三方插件——upx 脱壳</h3><p>安装upx（这里用brew安装）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install upx</span><br></pre></td></tr></table></figure><p>打开终端输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">upx -d &#39;&#x2F;Applications&#x2F;xxx.app&#x2F;Contents&#x2F;MacOS&#x2F;xxxx&#39;</span><br></pre></td></tr></table></figure><p>其中xxx代表你要安装的软件</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>除夕之日，预祝各位</p><p>暴富又变美，脱单不脱发</p><p>横批：新年胜旧年</p><p>嘿嘿嘿</p>]]></content>
      
      
      <categories>
          
          <category> 破解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 破解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记MagicBook （Pro）黑苹果安装系统安装教程</title>
      <link href="2021/02/03/%E8%AE%B0MagicBook%20%EF%BC%88Pro%EF%BC%89%E9%BB%91%E8%8B%B9%E6%9E%9C%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>2021/02/03/%E8%AE%B0MagicBook%20%EF%BC%88Pro%EF%BC%89%E9%BB%91%E8%8B%B9%E6%9E%9C%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="记MagicBook-（Pro）黑苹果安装系统安装教程"><a href="#记MagicBook-（Pro）黑苹果安装系统安装教程" class="headerlink" title="记MagicBook （Pro）黑苹果安装系统安装教程"></a>记MagicBook （Pro）黑苹果安装系统安装教程</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本来寒假安装以及之前都安装了好几次，但是都没有记录，导致每次想升级新系统都要浪费时间东找西凑，今天有点时间总结一下以防明日之我又在浪费时间</p><h2 id="BIOS的修改"><a href="#BIOS的修改" class="headerlink" title="BIOS的修改"></a>BIOS的修改</h2><p>开机前狂按F2进BIOS界面（蓝色的）</p><p>BIOS版本：1.09</p><p>安全启动: 关闭</p><p>保存并退出</p><p>PS:不关这个的话就会出现<strong>Boot Fail</strong>的画面提示</p><h2 id="选择OpenCore引导"><a href="#选择OpenCore引导" class="headerlink" title="选择OpenCore引导"></a>选择OpenCore引导</h2><h3 id="OpenCore是什么呢？"><a href="#OpenCore是什么呢？" class="headerlink" title="OpenCore是什么呢？"></a>OpenCore是什么呢？</h3><p>OpenCore(OC)是一种新的引导方式，随着越来越多的kexts开始放弃Clover,我相信提早使用OC会对你未来使用黑苹果会有很大的帮助。这是一个自然的现象，就像变色龙被Clover淘汰，而现在OC代替Clover也是大势所趋。</p><h3 id="OpenCore替代Clover学说"><a href="#OpenCore替代Clover学说" class="headerlink" title="OpenCore替代Clover学说"></a>OpenCore替代Clover学说</h3><p>所以OpenCore真的不想替代Clover么？这句话你信么？反正我是不信的。是谁中止了对AptioFixPkg的维护？是谁宣布Lilu、AppleALC、VirtualSMC、VoodooPS2、VoodooInput、WhateverGreen在未来的开发中不再刻意照顾Clover的兼容性的？以前我们还有Rehabman,但是他在tonymacx86活跃了7年后也隐退了。未来某一天，AppleALC的一条commit可能就会让Clover陷入无限重启、或者WhateverGreen的哪个Release可能就会让Clover开始卡Hash Check Retry#40,然后大家不得不换到OpenCore、因为acidanthera团队说了他们的开发不会刻意兼容Clover。</p><h3 id="为啥选择Opencore？"><a href="#为啥选择Opencore？" class="headerlink" title="为啥选择Opencore？"></a>为啥选择Opencore？</h3><p>1.从2019年9月以后，Acidanthera开发的内核驱动（Lilu,AppleALC等等）[不再会]在Clover上做兼容性测试<br>2.OpenCore更加注重系统的安全性，提供对OpenCore自身引导文件对加密，同时对文件保险箱(FileVault)有更强大的支持，在未来会支持UEFI安全启动<br>3.OpenCore启动FileVault(硬盘保险箱）加密的分区速度远超Clover<br>4.OpenCore支持基于boot.efi的原生开机快捷键支持<br>5.OpenCore使用更加先进的方法注入第三方内核扩展驱动（Kext)且与此同时不会破坏系统完整性保护<br>6.OpenCore通过读取启动磁盘设置的NVRAM变量，可以像白苹果一样支持在设置的启动磁盘切换默认引导项<br>7.支持给其它.efi驱动或引导工具加入参数<br>8.如下UEFI驱动被合并入OpenCore,未来的开发直接与OpenCore绑定，且不再支持Clover</p><h3 id="OpenCore-的配置为什么看起来这么复杂？"><a href="#OpenCore-的配置为什么看起来这么复杂？" class="headerlink" title="OpenCore 的配置为什么看起来这么复杂？"></a>OpenCore 的配置为什么看起来这么复杂？</h3><p>OpenCore为了提高兼容性，为用户开放了更多底层的QuirkOpenCore现阶段没有可用的非常直观的GUI编辑器换位思考，如果用Xcode来编辑Clover安装包内自带的Config样本，显然OpenCore会更简单。OpenCore很多功能都有且只有一处设置，但是Clover有大量等效组合互相干扰。</p><h3 id="Acidanthera的野心"><a href="#Acidanthera的野心" class="headerlink" title="Acidanthera的野心"></a>Acidanthera的野心</h3><p>黑苹果突然这么被动了？acidanthera几乎垄断了黑苹果。SMC模拟的VirtualSMC、声卡的AppleALC、核显的WhateverGreen、蓝牙的BrcmPatchRAM、键盘、鼠标和触摸板的VoodooPS2和VoodooInput,几乎黑苹果所有的内核驱动都是acidanthera开发的、而且没有替代品。如果它们不再刻意兼容Clover,出了问题你就只能被迫换到OpenCore、你没有其它选择。</p><h2 id="解锁CFG-Lock-amp-DVMT"><a href="#解锁CFG-Lock-amp-DVMT" class="headerlink" title="解锁CFG-Lock&amp;DVMT"></a>解锁CFG-Lock&amp;DVMT</h2><p>（OpenCore引导必备，如果你选择Clover引导可以跳过此步）</p><p>方法一：</p><p>（请非常非常非常小心谨慎！如果出现问题可能导致需要更换主板！！！！！！！！！）</p><p>MagicBook 2018的请下拉至蓝色字体处！</p><p>解答：<a href="https://zhidao.baidu.com/question/456790415108635365.html">CFG-Lock是什么？</a>；为什么要修改DVMT：为了使HDMI接口能输出4k分辨率，此处请注意，使用OpenCore必须同时修改CFG和DVMT，如果出现进度条只走一半就重启，或者卡在进度条的起点等奇怪现象，就别怪没在这提醒你嗷！————此教程特别特别特别感谢“京子”嘿嘿 </p><p>首先将RU.efi放入EFI分区根目录（像放Clover的EFI文件夹一样操作）</p><p>使用easyUEFI设置RU.efi为启动项，类型选Linux，名字随便起，记得住就行（像设置Clover64.efi一样操作）</p><p>① 重启，出现此界面</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203205939797.png" alt="image-20210203205939797"></p><p>② 按下alt和=</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210016534.png" alt="image-20210203210016534"></p><p>③ 按方向键下键，找到cpusetup，回车</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210104265.png" alt="image-20210203210104265"></p><p>④ 使用方向键，定位并更改003E位置（只看绿色底并且两位数的位置，长条八位数那个不用管它）的“01”为00，回车</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210123724.png" alt="image-20210203210123724"></p><p>按下Ctrl+W保存，然后按下alt和= 回到上一级界面，寻找SaSetup，定位到0107位置（需要按Ctrl+Fn+↓翻页）从01改成02，步骤和上面一模一样，记得按下Ctrl+W保存！</p><p>Ctrl+Alt+Del重启，按F12进入Windows将此启动项删除</p><p>方法二：借助Insyde的官方工具对BIOS进行修改，以下会介绍GUI方法来修改CFG-Lock和DVMT Pre-Allocated数值</p><p>文件地址：<a href="https://4m.cn/fW3yp">https://4m.cn/fW3yp</a></p><p>注意：以下的所有操作均会涉及BIOS，稍有不慎就会导致主板损坏，无法开机，如果决定跟着做，请务必小心谨慎，不可跳步，漏步！！！</p><p>如果电脑使用的是Windows Defender，请在“执行操作”里面对此程序选“允许”</p><p>（此为2019机型的步骤，2018的对应位置请下拉至蓝色字体处）</p><p>打开InsydeH2OUVE文件夹，先以管理员身份运行WDFInst.exe安装工具驱动</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210236040.png" alt="image-20210203210236040"></p><p>以管理员身份运行H2OUVE-W-GUIx64.exe程序</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210236040.png"></p><p>选择File – Load runtime读取当前BIOS状态</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203210310135.png" alt="image-20210203210310135"></p><p>选择左侧Variable菜单，获取当前BIOS变量</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20210203212319.png"></p><p>找到名称为SaSetup的空间（双击后可看到该空间内的所有变量，可根据最后一个变量所在的偏移地址得出空间大小，与步骤0中的空间大小比对，从而确定找到的空间是正确的），并找到偏移量为0x107的数值</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20210203212350.png"></p><p>修改该数值的01为02（确认该空间被选中——前方的√打上,此处可以先不着急按左上角的保存按钮）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212417808.png" alt="image-20210203212417808"></p><p>然后找到CpuSetup 003E的位置，双击，修改该数值的01为00</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212450626.png" alt="image-20210203212450626"></p><p>确保两个√都打上以后，点击左上角的按钮保存（Sastup和CpuSetup的位置可能不在一起，只要确保修改位置正确、√都打上了就没问题，记得保存！）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212501315.png" alt="image-20210203212501315"></p><p>看到提示保存变量成功的提示后，说明已修改成功，此时可重启电脑让其生效。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212511383.png" alt="image-20210203212511383"></p><p>如何测试是否修改成功？使用对应的config.plist能进入系统的话，即说明修改成功，可文中图片加以识别！ </p><p>以上为2019&amp;2020 MagicBook（Pro）的位置，Magicbook 2018的位置：</p><p>Cfg-lock：CPUsetup 0x3c 01改成00</p><p>DVMT：Sasetup 0xDF 01改成 02</p><h2 id="Win系统下苹果系统镜像U盘制作"><a href="#Win系统下苹果系统镜像U盘制作" class="headerlink" title="Win系统下苹果系统镜像U盘制作"></a>Win系统下苹果系统镜像U盘制作</h2><ol><li><p>系统下载：建议到黑果小兵的部落阁下载最新的镜像文件：<a href="https://blog.daliansky.net/">https://blog.daliansky.net/</a></p></li><li><p>群文件或者其他地方下载etcher</p></li><li><p>准备一个8GB以上的U盘（建议16G）</p></li><li><p>用管理员身份打开etcher，记住一定要用管理员身份打开</p></li><li><p>按图片教程写入苹果原版镜像</p></li></ol><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212524475.png" alt="image-20210203212524475"></p><p>Etcher操作非常简单，说白了就三步↑</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212534524.png" alt="image-20210203212534524"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212547304.png" alt="image-20210203212547304"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203212601351.png" alt="image-20210203212601351"></p><p>然后静等写入成功！</p><p>4.分区准备（会用diskgenius的话也可以自己操作）</p><p>A． 确认GPT分区表，esp(EFI分区)大小：现在黑果安装一般使用UEFI+GPT的方法安装苹果原版镜像。苹果系统安装要求efi分区大小要是200MB及以上，否则在苹果安装磁盘工具界面无法将磁盘格成苹果要求的APFS或者HFS+系统格式小Y原装win8的，基本不需要考虑这步，一般是GPT格式+260MB的esp分区大小。</p><p>B． 自己改装UEFI引导win7或者win10的，可能之前会不太注意esp分区的大小。直接用系统装的话esp分区大小会是100MB，需要进行efi分区扩容。当然还有改装MBR分区表win7的，建议进PE直接整个磁盘格成GPT格式，新建200MB的EFI分区。</p><p>C .还有机友加了磁盘的，请注意如果这个磁盘用来安装mac的话，也要是GPT格式的，efi分区大小是200MB及以上的，不然就是你另一块放有clover引导的磁盘efi分区符合要求，也可能会格不了盘的。</p><p>D.给大家看一下正确的磁盘分区格式吧，大家一般看我的磁盘2的那个分区就是了。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213222389.png" alt="image-20210203213222389"></p><p>E.再给大家看一下所谓的esp（efi）分区：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213238926.png" alt="image-20210203213238926"></p><p>F.新建一个分区，用来安装mac,这个是基操了，右键管理，进磁盘管理，选择一个现有分区，右键选择压缩卷，大小自己看吧，跟装windows一样，一直默认下一步就是。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213249814.png" alt="image-20210203213249814"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213259952.png" alt="image-20210203213259952"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213309800.png" alt="image-20210203213309800"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213319692.png" alt="image-20210203213319692"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213327960.png" alt="image-20210203213327960"></p><p>5.创建系统引导</p><p>直接使用OC引导Windows10会出现很多奇奇怪怪的问题，因此，在OC引导下想用Win10就要在开机前按F12选择“Windows Boot Manager”或者：（推荐）将群文件“群主的OC”文件夹里面的Refind或者bootmenu放进EFI分区（方法接下来就能看到），然后用easyUEFI将其设置成第一启动项（方法和设置Clover64.efi;OpenCore.efi一模一样）</p><p>1.从群文件中下载所需的clover/OC附件,建议下载最新版。</p><p>2.用磁盘管理软件如DiskGenius，BOOTICE啊给内置硬盘的esp(efi)分区分配一个盘符，请注意，使用已经弄好的clover，放内置硬盘，带clover的镜像写入生成的那个在U盘中的不需要管。</p><p>3.打开esp(efi)分区，如果提示安全权限打不开的话，找到记事本程序，用管理员身份打开，点击文件-打开，选择esp(efi)盘，将配好的clover拖入esp(efi)盘的EFI文件夹就是。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213337774.png" alt="image-20210203213337774"></p><p>4.解压clover/OC附件</p><p>A.将附件中的boot文件夹替换esp(efi)分区中efi文件夹的BOOT文件夹。</p><p>B.将自己配好的clover/OC文件夹放入esp(efi)分区中efi文件夹中 </p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213350249.png" alt="image-20210203213350249"></p><p>5.管理员身份打开EasyUEFI（注：OC的路径为**EFIOCOpenCore.efi；</p><p>Refind的路径为EFIRefindrefind_x64.efi；</p><p>BootMenu的路径为EFIBootMenuBootMenu.efi）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213359573.png" alt="image-20210203213359573"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213408825.png" alt="image-20210203213408825"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213422597.png" alt="image-20210203213422597"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213432084.png" alt="image-20210203213432084"></p><p>注：OC（单系统推荐）的路径为**EFIOCOpenCore.efi、</p><p>Refind（多系统推荐）的路径为EFIRefindrefind_x64.efi；</p><p>BootMenu（多系统推荐）的路径为EFIBootMenuBootMenu.efi</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213441506.png" alt="image-20210203213441506"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213450213.png" alt="image-20210203213450213"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213500297.png" alt="image-20210203213500297"></p><h2 id="系统安装"><a href="#系统安装" class="headerlink" title="系统安装"></a>系统安装</h2><p>大概说一下我的黑果安装过程作参考吧 （PS:装黑果要有耐心，特别是走安装进度条的时候。要记住：同机型能装的，没道理你的不能装。）mac系统安装步骤跟win一样，都是复制-展开-安装-设置套路走的。同时也会有多次正常重启。</p><p>正常来说，如果成功设置了OC为默认启动项，直接重启计算机会出现这个界面，我们选择：Install macOS Catalina，当然我这里有5个是因为我已经安装过这么多，你的第1个也可能是其它的东西，我们可以按键盘上下键来选择至Install macOS Catalina，然后Enter回车（小技巧：在这个界面按下Ctrl+Enter回车可以设置某个引导为默认启动项，当然现在先不要设置，等一切安装好以后再设置）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213510554.png" alt="image-20210203213510554"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213518425.png" alt="image-20210203213518425"></p><p>1.进安装界面，磁盘工具抹安装分区盘，然后选盘安装，此时安装程序会像win一样复制安装镜像到安装分区盘，进度条剩余时长由硬盘读写能力决定，一般几分钟，然后系统自动重启，第一步镜像复制完成。如果引导在内置硬盘EFI中，后面就没U盘啥事了，如果引导在U盘中，注意保护好U盘，别乱碰到了哈。 </p><p>跟win一样选择磁盘工具（磁盘管理进行格盘操作）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213527069.png" alt="image-20210203213527069"></p><p>选择要安装的盘。点抹掉</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213535146.png" alt="image-20210203213535146"></p><p>苹果分区格式，固态硬盘选择APFS，机械硬盘选择Mac OS扩展（日志式）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213546715.png" alt="image-20210203213546715"></p><p>给新建APFS起个自定义卷标名吧，我一般是macOS的，然后点抹掉</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213556754.png" alt="image-20210203213556754"></p><p>自动跳到这个界面，当然是选择安装了</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213626235.png" alt="image-20210203213626235"></p><p>跟win一样选择安装盘进行安装</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213635117.png" alt="image-20210203213635117"></p><p>这就是镜像复制了，是不是跟win安装的套路差不多</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213644103.png" alt="image-20210203213644103"></p><p>2.重启后进入第二步，看到clover/oc界面，系统会默认选择你要安装系统的盘进入（意思是不要乱按乱选择），名字是boot install macOS from XXX,XXX为你要安装系统的分区名，而不是你的U盘。苹果进度条走到3/4时，系统自动重启。第二步镜像展开完成。</p><p>3.重启后，正常是此时系统会继续默认选择你要安装系统的盘进入，然后进入第三步，镜像安装。苹果进度条会走到上一步的3/4，然后出现安装剩余时间的提示，默默等安装走进度条就是了。安装完后系统自动重启，第三步镜像安装完成。</p><p>这个就是国家地区选择界面了，有点糊啊，默认选择第一项中国</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213652394.png" alt="image-20210203213652394"></p><p>键盘我一般是默认的路过</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213704010.png" alt="image-20210203213704010"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213711003.png" alt="image-20210203213711003"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213721023.png" alt="image-20210203213721023"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213734168.png" alt="image-20210203213734168"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213753297.png" alt="image-20210203213753297"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213802522.png" alt="image-20210203213802522"></p><p>跟win一样，创建本地账户，不过有一点mac不像win，一定要设置密码。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213812459.png" alt="image-20210203213812459"></p><p>一向操作是勾掉反馈</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213820575.png" alt="image-20210203213820575"></p><p>不用说，能开siri,当然是开了</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213829955.png" alt="image-20210203213829955"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213846315.png" alt="image-20210203213846315"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213856399.png" alt="image-20210203213856399"></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203213908038.png" alt="image-20210203213908038"></p><p>当当当，大功告成了</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/%E6%88%AA%E5%B1%8F2021-02-03%2021.391.43.png" alt="截屏2021-02-03 21.391.43"></p><p>注意事项：<br>1.机械硬盘由于读写能力可能会在安装进度条走剩余时长时在剩余最后一分钟的时候会走很长时间，没办法，等进度条走完就是，固态硬盘就要好好多</p><p>2.魔法书可跟白果一样在线系统升级，请注意，系统安装在PM981硬盘上面的话暂时不可进行系统升级</p><h2 id="Clover-替换OC"><a href="#Clover-替换OC" class="headerlink" title="Clover 替换OC"></a>Clover 替换OC</h2><p>解决 Clover 和 OpenCore 的冲突</p><p>在重启进入 OpenCore 之前, 我们还需要解决一些冲突问题:</p><p>（以下内容转自黑果小兵的博客<a href="https://blog.daliansky.net/OpenCore-BootLoader.html%EF%BC%89">https://blog.daliansky.net/OpenCore-BootLoader.html）</a></p><p>（其实就是把所有代码都输入“终端”运行！</p><p>可以大段复制粘贴）</p><p>①删除 Clover 设置面板</p><p>Clover 设置面板会和 OpenCore 产生冲突, 需要删除</p><p>Clover 设置面板位于 /Library/PreferencePanes/Clover.prefPane</p><p>终端输入 sudo rm -rf /Library/PreferencePanes/Clover.prefPane 删除</p><p>清理 Clover 的模拟 NVRAM RC 脚本 和 守护程序 CloverDaemonNew</p><h1 id="删除-RC-脚本"><a href="#删除-RC-脚本" class="headerlink" title="删除 RC 脚本"></a>删除 RC 脚本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.clover.lib&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.boot.d&#x2F;10.save_and_rotate_boot_log.local&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.boot.d&#x2F;20.mount_ESP.local&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.boot.d&#x2F;70.disable_sleep_proxy_client.local.disabled&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.boot.d&#x2F;80.save_nvram_plist.local&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.shutdown.local&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.boot.d&quot;</span><br><span class="line"></span><br><span class="line">rm -rf &quot;&#x2F;etc&#x2F;rc.shutdown.d&quot;</span><br></pre></td></tr></table></figure><h1 id="删除-Clover-新开发的-NVRAM-守护程序-CloverDaemonNew"><a href="#删除-Clover-新开发的-NVRAM-守护程序-CloverDaemonNew" class="headerlink" title="删除 Clover 新开发的 NVRAM 守护程序 CloverDaemonNew"></a>删除 Clover 新开发的 NVRAM 守护程序 <code>CloverDaemonNew</code></h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">launchctl unload &#39;&#x2F;Library&#x2F;LaunchDaemons&#x2F;com.slice.CloverDaemonNew.plist&#39;</span><br><span class="line"></span><br><span class="line">rm -rf &#39;&#x2F;Library&#x2F;LaunchDaemons&#x2F;com.slice.CloverDaemonNew.plist&#39;</span><br><span class="line"></span><br><span class="line">rm -rf &#39;&#x2F;Library&#x2F;Application Support&#x2F;Clover&#x2F;CloverDaemonNew&#39;</span><br><span class="line"></span><br><span class="line">rm -rf &#39;&#x2F;Library&#x2F;Application Support&#x2F;Clover&#x2F;CloverLogOut&#39;</span><br><span class="line"></span><br><span class="line">rm -rf &#39;&#x2F;Library&#x2F;Application Support&#x2F;Clover&#x2F;CloverWrapper.sh&#39;</span><br></pre></td></tr></table></figure><p>终端执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo spctl --master-disable</span><br><span class="line"></span><br><span class="line">sudo kextcache -i &#x2F;</span><br></pre></td></tr></table></figure><p>再重启进Windows，进行启动项的设置（<a href="#easyUEFI">easyUEFI</a>），然后再次重启 </p><p>再次重启后的步骤：</p><p>第一次重启以后需要选择下图的 Reset  NVRAM（输入对应的数字键然后回车，和我的图数字位置不一定一样）；图形化的OpenCore引导（目前未更新）使用键盘上的→按键选择Reset NVRAM</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210203214509413.png" alt="image-20210203214509413"></p><p>Reset NVRAM以后，会自动进入Windows10，因为这个Reset会清除启动项建立的操作（也就是刚才easyUEFI的操作），需要完完整整不跳步地重新再操作一次（目的是重新建立引导），即可。</p><p>然后再次重启：选中 Mac 进系统（默认设置了停留3秒自动进入）</p><p>就完成了Clover 转换 OC ！</p><h2 id="注入三码"><a href="#注入三码" class="headerlink" title="注入三码"></a>注入三码</h2><p>1.第一步，下载群文件里面的OpenCore Configurator，看最上面，找到和这个一模一样的地方，点击挂载EFI</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/1.%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%8C%E4%B8%8B%E8%BD%BD%E7%BE%A4%E6%96%87%E4%BB%B6%E9%87%8C%E9%9D%A2%E7%9A%84OpenCore%20Configurator%EF%BC%8C%E7%9C%8B%E6%9C%80%E4%B8%8A%E9%9D%A2%EF%BC%8C%E6%89%BE%E5%88%B0%E5%92%8C%E8%BF%99%E4%B8%AA%E4%B8%80%E6%A8%A1%E4%B8%80%E6%A0%B7%E7%9A%84%E5%9C%B0%E6%96%B9%EF%BC%8C%E7%82%B9%E5%87%BB%E6%8C%82%E8%BD%BDEFI.png" alt="1.第一步，下载群文件里面的OpenCore Configurator，看最上面，找到和这个一模一样的地方，点击挂载EFI"></p><p>2.选择(挂载分区)，然后输入密码确定，然后点(打开分区)</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/2.%E9%80%89%E6%8B%A9(%E6%8C%82%E8%BD%BD%E5%88%86%E5%8C%BA)%EF%BC%8C%E7%84%B6%E5%90%8E%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81%E7%A1%AE%E5%AE%9A%EF%BC%8C%E7%84%B6%E5%90%8E%E7%82%B9(%E6%89%93%E5%BC%80%E5%88%86%E5%8C%BA).png" alt="2.选择(挂载分区)，然后输入密码确定，然后点(打开分区)"></p><p>3.在新分区中找到图片的位置，然后按图操作，用OCG打开config</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/3.%E5%9C%A8%E6%96%B0%E5%88%86%E5%8C%BA%E4%B8%AD%E6%89%BE%E5%88%B0%E5%9B%BE%E7%89%87%E7%9A%84%E4%BD%8D%E7%BD%AE%EF%BC%8C%E7%84%B6%E5%90%8E%E6%8C%89%E5%9B%BE%E6%93%8D%E4%BD%9C%EF%BC%8C%E7%94%A8OCG%E6%89%93%E5%BC%80config.png" alt="3.在新分区中找到图片的位置，然后按图操作，用OCG打开config"></p><p>4.如图顺序进行设置，参考clover的三码教程来确定（序列号无效），别忘了保存！</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/4.%E5%A6%82%E5%9B%BE%E9%A1%BA%E5%BA%8F%E8%BF%9B%E8%A1%8C%E8%AE%BE%E7%BD%AE%EF%BC%8C%E5%8F%82%E8%80%83clover%E7%9A%84%E4%B8%89%E7%A0%81%E6%95%99%E7%A8%8B%E6%9D%A5%E7%A1%AE%E5%AE%9A%EF%BC%88%E5%BA%8F%E5%88%97%E5%8F%B7%E6%97%A0%E6%95%88%EF%BC%89%EF%BC%8C%E5%88%AB%E5%BF%98%E4%BA%86%E4%BF%9D%E5%AD%98%EF%BC%81.png" alt="4.如图顺序进行设置，参考clover的三码教程来确定（序列号无效），别忘了保存！"></p><h2 id="跳过OC引导界面"><a href="#跳过OC引导界面" class="headerlink" title="跳过OC引导界面"></a>跳过OC引导界面</h2><p>接上进入Misc-其他设置，取消勾选ShowPicker</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/%E6%88%AA%E5%B1%8F2021-02-03%2018.30.50.png" alt="截屏2021-02-03 18.30.50"></p><h2 id="进入系统的一些优化"><a href="#进入系统的一些优化" class="headerlink" title="进入系统的一些优化"></a>进入系统的一些优化</h2><p>每次OpenCore更新都要看一看压缩包里面的更新日志，里面有非常重要的注意事项！</p><ol><li>开启任何来源:</li></ol><p>在终端中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo spctl --master-disable</span><br></pre></td></tr></table></figure><ol start="2"><li>安装群文件：双系统时间同步补丁,Win下导入后重启即可</li></ol><p>Win和mac实现时间同步，不然好像会相差8个小时</p><ol start="3"><li>工具和一些软件群文件里有提供，善用搜索功能</li></ol><p>注意！如果上述步骤未完成，会出现各种奇奇怪怪的BUG！！！</p><p>参考：</p><ul><li><a href="https://github.com/GatesYang/Magicbook-Pro-16.1-Hackintosh">Magicbook-(Pro)-16.1-Hackintosh-2019&amp;2020 黑苹果稳定版</a>如果你是MagicBook系列用户，强烈建议加一下里面的群</li><li><a href="https://www.bilibili.com/video/BV14E411G7Ww?t=1074">视频安装Clover/OpenCore</a></li><li><a href="https://www.bilibili.com/video/BV1s741187on?t=16">锐龙版安装视频教程</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 黑苹果 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 黑苹果 </tag>
            
            <tag> 多系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac下Aria2c安装配置（附Win版Aria2懒人包）</title>
      <link href="2021/02/02/Mac%E4%B8%8BAria2c%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%EF%BC%88%E9%99%84Win%E7%89%88Aria2%E6%87%92%E4%BA%BA%E5%8C%85%EF%BC%89/"/>
      <url>2021/02/02/Mac%E4%B8%8BAria2c%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%EF%BC%88%E9%99%84Win%E7%89%88Aria2%E6%87%92%E4%BA%BA%E5%8C%85%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="Mac下Aria2c安装配置（附Win版Aria2懒人包）"><a href="#Mac下Aria2c安装配置（附Win版Aria2懒人包）" class="headerlink" title="Mac下Aria2c安装配置（附Win版Aria2懒人包）"></a>Mac下Aria2c安装配置（附Win版Aria2懒人包）</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Mac系统还是有诸多不便，破解软件、软件库等资源相较于Win要少，不过用起来还是清爽有时甚至可以装X哈哈哈哈哈啊哈哈！说正题，Mac用不了亿寻、KinhDown、PD改造版等毒盘不限速神器，因为开发者基本只照顾到了Win用户、甚至是安卓用户，难道这方面的大佬都用的Win？？？不过它们的原理基本都有Aria2原理+建立VIP账号Cookies池+找到的接口等，而我查了一下资料，前几年Aria2下载以及下载毒盘资源还是异常火爆的，但近几年由于毒盘可能加了防范措施还有国内种子被某雷封锁，热度特别是在Mac上骤减。当然个人感觉，因为网上教程大多是17、18年的而且配置Aria2对小白还是有门槛的，这里记录一下Mac的简单配置，并且附录Win版Aria2懒人包。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20190816150245.jpg"></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>Aria2作者在<a href="https://github.com/aria2/aria2">github</a>以及<a href="https://aria2.github.io/">官网</a>已经有很多介绍和教程，这里我用Homebrew安装。前提是你已经安装好了Homebrew（<a href="https://zhuanlan.zhihu.com/p/111014448">没安装的参考这个</a>），然后正常打开终端键入命令安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install aria2</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置是重中之重，很多人都在这里跳了不少坑</p><h3 id="下载配置文件（二选一）"><a href="#下载配置文件（二选一）" class="headerlink" title="下载配置文件（二选一）"></a>下载配置文件（二选一）</h3><ul><li>Aria2相关配置百度云：<a href="https://pan.baidu.com/s/1sYWQYOU4ZJnPTOmuApw-yQ">https://pan.baidu.com/s/1sYWQYOU4ZJnPTOmuApw-yQ</a> 密码：h1ep</li><li>Aria2相关配置自建云盘：<a href="https://4m.cn/ohE87">https://4m.cn/ohE87</a></li></ul><h3 id="新建建立aria2文件夹"><a href="#新建建立aria2文件夹" class="headerlink" title="新建建立aria2文件夹"></a>新建建立aria2文件夹</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 打开终端默认在当前用户文件夹下，然后创建aria2文件夹</span><br><span class="line">mkdir ~/.aria2</span><br></pre></td></tr></table></figure><h3 id="打开刚才创建好的aria2文件夹"><a href="#打开刚才创建好的aria2文件夹" class="headerlink" title="打开刚才创建好的aria2文件夹"></a>打开刚才创建好的aria2文件夹</h3><p>可以这样：</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> ~/.aria2</span><br></pre></td></tr></table></figure><p>也可以这样：</p><p>在访达里Command+Shift+.可以看到隐藏文件夹，然后打开配隐藏的刚刚新建的aria2文件夹，像Win一样可视化操作</p><h3 id="解压下载好的配置文件，将下列文件放到到aria2文件夹内"><a href="#解压下载好的配置文件，将下列文件放到到aria2文件夹内" class="headerlink" title="解压下载好的配置文件，将下列文件放到到aria2文件夹内"></a>解压下载好的配置文件，将下列文件放到到aria2文件夹内</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">aria2</span><span class="selector-class">.conf</span></span><br><span class="line"><span class="selector-tag">aria2</span><span class="selector-class">.log</span></span><br><span class="line"><span class="selector-tag">aria2</span><span class="selector-class">.session</span></span><br><span class="line"><span class="selector-tag">com</span><span class="selector-class">.aria2c</span><span class="selector-class">.plist</span></span><br><span class="line"><span class="selector-tag">com</span><span class="selector-class">.google</span><span class="selector-class">.Chrome</span><span class="selector-class">.mobileconfig</span></span><br></pre></td></tr></table></figure><h3 id="将下载文件夹内的-aria2c-文件复制到-usr-local-Cellar-aria2-1-35-0-bin-下"><a href="#将下载文件夹内的-aria2c-文件复制到-usr-local-Cellar-aria2-1-35-0-bin-下" class="headerlink" title="将下载文件夹内的 aria2c 文件复制到 /usr/local/Cellar/aria2/1.35.0/bin 下"></a>将下载文件夹内的 aria2c 文件复制到 /usr/local/Cellar/aria2/1.35.0/bin 下</h3><p> 终端输入命令进入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/aria2/1.35.0/bin</span><br></pre></td></tr></table></figure><p>也可以像刚才可视化界面进入</p><p>将该文件夹里的 aria2c 文件重命名为 aria2c.bak，再将下载文件夹内的 aria2c 复制进去<br><strong>注意：</strong><br> <strong>1.理由是官方的 aria2c 版本最多支持16线程，sarkrui改好的aria2c版本支持128线程</strong><br> <strong>2.文中所说的1.35.0是我当前从brew上下载下来的版本，实际以你brew下载下来的版本为准，如果和我版本不一致，请修改相关的1.35.0这个路径</strong></p><h3 id="右键使用文本编辑或vscode打开-aria2-conf"><a href="#右键使用文本编辑或vscode打开-aria2-conf" class="headerlink" title="右键使用文本编辑或vscode打开 aria2.conf"></a>右键使用文本编辑或vscode打开 aria2.conf</h3><p> <strong>找到如下语句，将hsuyelin(本人电脑用户名)修改为你电脑的用户，修改完成 command+s 保存退出</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#文件保存路径, 默认为当前启动位置</span></span><br><span class="line">dir=/Users/hsuyelin/Downloads</span><br><span class="line"><span class="comment"># 日志保存路径</span></span><br><span class="line"><span class="built_in">log</span>=/Users/hsuyelin/.aria2/aria2.log</span><br><span class="line"><span class="comment"># 从会话文件中读取下载任务</span></span><br><span class="line">input-file=/Users/hsuyelin/.aria2/aria2.session</span><br><span class="line"><span class="comment"># 在Aria2退出时保存`错误/未完成`的下载任务到会话文件</span></span><br><span class="line">save-session=/Users/hsuyelin/.aria2/aria2.session</span><br></pre></td></tr></table></figure><h3 id="右键使用文本编辑或vscode打开-com-aria2c-plist"><a href="#右键使用文本编辑或vscode打开-com-aria2c-plist" class="headerlink" title="右键使用文本编辑或vscode打开 com.aria2c.plist"></a>右键使用文本编辑或vscode打开 com.aria2c.plist</h3><p> <strong>找到如下语句，将hsuyelin(个人人电脑用户名)修改为你电脑的用户，修改完成 command+s 保存退出</strong></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--conf-path=<span class="regexp">/Users/hsuyelin</span><span class="regexp">/.aria2/aria</span>2.conf</span><br></pre></td></tr></table></figure><h3 id="安装-Aria2-GUI-软件"><a href="#安装-Aria2-GUI-软件" class="headerlink" title="安装 Aria2 GUI 软件"></a>安装 Aria2 GUI 软件</h3><p> 将附件里的 Aria2 GUI.app 复制到 /Applications 目录下</p><h2 id="试运行aria2服务"><a href="#试运行aria2服务" class="headerlink" title="试运行aria2服务"></a>试运行aria2服务</h2><p>终端输入以下命令，输入如果未报错，那么Aria2服务正常运行了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aria2c</span><br></pre></td></tr></table></figure><p><strong>注：如果报6800错误，那么将 aria2.conf 文件里的下列语句进行修改</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#RPC端口, 仅当默认端口被占用时修改</span></span><br><span class="line">rpc-listen-port=6800</span><br></pre></td></tr></table></figure><h2 id="配置开机自启（可选）"><a href="#配置开机自启（可选）" class="headerlink" title="配置开机自启（可选）"></a>配置开机自启（可选）</h2><p>将附件包里的 com.aria2c.plist 复制到 /Users/你的用户名/.aria2/ 目录下，也就是和刚才复制配置aria2.conf在一个文件夹，然后把 com.aria2c.plist 复制到打开的LaunchAgents文件夹里：</p><p>可以键入以下命令</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">open ~<span class="regexp">/Library/</span>LaunchAgents</span><br><span class="line">launchctl load -w ~<span class="regexp">/Library/</span>LaunchAgents/com.aria2c.plist</span><br></pre></td></tr></table></figure><p>或者可视化界面复制粘贴</p><h2 id="Win下使用"><a href="#Win下使用" class="headerlink" title="Win下使用"></a>Win下使用</h2><p>直接下载<a href="https://citpan.herokuapp.com/CITpan/CIT%E5%B0%8F%E7%BB%84%E8%B5%84%E6%BA%90/%E6%AF%92%E7%9B%9820210121%E6%9C%80%E6%96%B0%E4%B8%8D%E9%99%90%E9%80%9F%E7%BD%91%E9%A1%B5%E7%89%88%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/Aria2.zip?preview">Win版Aria2懒人包</a>+<a href="https://citpan.herokuapp.com/CITpan/CIT%E5%B0%8F%E7%BB%84%E8%B5%84%E6%BA%90/%E6%AF%92%E7%9B%9820210121%E6%9C%80%E6%96%B0%E4%B8%8D%E9%99%90%E9%80%9F%E7%BD%91%E9%A1%B5%E7%89%88%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/%E6%AF%92%E7%9B%9820210121%E6%9C%80%E6%96%B0%E4%B8%8D%E9%99%90%E9%80%9F%E7%BD%91%E9%A1%B5%E7%89%88%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.mp4?preview">使用视频</a>食用</p><h2 id="Aria2用途"><a href="#Aria2用途" class="headerlink" title="Aria2用途"></a>Aria2用途</h2><p>HTTP 下载和 BT 下载、配合不太稳定的插件或者脚本下载毒盘文件(虽然)等</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Aria2，你值得试一试</p><p>参考：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/161388489">轻量化后台下载工具 Aria2c安装配置 | for Mac</a></li><li><a href="https://www.jianshu.com/p/97efbb73a747">Mac下Aria2加速各种网盘下载，你值得拥有！</a></li><li><a href="https://www.jianshu.com/p/74ab7c2053ac">Mac下Aria2安装及其配置并设置开机启动（某云黑科技）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Aria2 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Aria2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cloud Sharing</title>
      <link href="2021/02/01/Cloud%20Sharing/"/>
      <url>2021/02/01/Cloud%20Sharing/</url>
      
        <content type="html"><![CDATA[<h1 id="Cloud-Sharing"><a href="#Cloud-Sharing" class="headerlink" title="Cloud Sharing"></a>Cloud Sharing</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>害手抖把蓝奏云的网盘整理了一下，结果蓝奏云有机制——分享的链接其他人只能看到文件。也就是说我现在虽然将全部的文件通过新建文件夹的方式分了一下类，但其他人不能通过最顶层的分享链接查看最下面文件夹的内容。无奈，特此把每个分类的文件夹链接放到博客，以供大家点击跳转到分享页面。</p><p>注意：</p><ul><li>建议官方下载的文件是官方免费无需pj，而且官方实时更新，我这里只是留存旧版本</li><li>不当使用造成后果本站及本人概不负责，因此建议你食用前先百度或谷歌一下软件名</li><li>所有资源全部来自互联网收集，仅供交流学习，用完请立即删除</li></ul><h2 id="CIT小软件资料类（单文件≤100M）（密码全为cit）"><a href="#CIT小软件资料类（单文件≤100M）（密码全为cit）" class="headerlink" title="CIT小软件资料类（单文件≤100M）（密码全为cit）"></a><a href="https://cit.lanzous.com/b01npfu1g">CIT小软件资料类</a>（单文件≤100M）（密码全为cit）</h2><ul><li><a href="https://cit.lanzous.com/b01nzf1kb">市场调研 [一些关于市场调研比赛…]</a><ul><li><a href="https://cit.lanzous.com/b01nzf2he">2021.1.16市调大赛线上培训会培训课件 [2021.1.16市调大赛线…]</a></li></ul></li><li><a href="https://cit.lanzous.com/b01nzf36j">同屏软件 [AnLink等]</a></li><li><a href="https://cit.lanzous.com/b01nzf3eh">磁盘扩容分区修复等、引导修复 [DiskGenius——磁盘分…]</a></li><li><a href="https://cit.lanzous.com/b01nzf3ha">Pycharm专业版激活 [推荐ide-eval-resette…]</a></li><li><a href="https://cit.lanzous.com/b01nzf3pi">科学上网 [傻瓜式科学上网 但效…]</a></li><li><a href="https://cit.lanzous.com/b01nzf3tc">视频播放器 [优秀视频播放器…]</a></li><li><a href="https://cit.lanzous.com/b01nzf42b">CIT_Teaching [一些教学后收集的成果…]</a></li><li><a href="https://cit.lanzous.com/b01nzf46f">Win激活 [激活Win，kms建议去官方…]</a></li><li><a href="https://cit.lanzous.com/b01nzf4fe">移除pdf密码限制 [移除pdf密码限制…]</a></li><li><a href="https://cit.lanzous.com/b01nzf4va">下载神器 [win多线程建议IDM、ma…]</a></li><li><a href="https://cit.lanzous.com/b01nzf4va">毒盘不限速下载 [毒盘不限速下载，变化大…]</a></li><li><a href="https://cit.lanzous.com/b01nzf52h">向日葵远控pj [HRK主控端，适用于win …]</a></li><li><a href="https://cit.lanzous.com/b01nzf5bg">压缩软件 [一些压缩软件去广告，建…]</a></li><li><a href="https://cit.lanzous.com/b01nzf5ni">win强力卸载软件pj [win强力卸载软件pj…]</a></li><li><a href="https://cit.lanzous.com/b01nzf66h">QQ资料清空保护隐私 [QQ资料清空保护隐私，但…]</a></li><li><a href="https://cit.lanzous.com/b01nzf6ef">图片查看器 [一些比较好的图片查看…]</a></li><li><a href="https://cit.lanzous.com/b01nzf6ja">给系统安装插接件 [建议去官网，免费…]</a></li><li><a href="https://cit.lanzous.com/b01nzf70h">win10运行内存清理 [让win10运行内存小的…]</a></li><li><a href="https://cit.lanzous.com/b01nzf75c">win10升级最新版win10 [建议去官方，免费…]</a></li><li><a href="https://cit.lanzous.com/b01nzf78f">百度、豆丁文库等下载 [也可以用脚本]</a></li><li><a href="https://cit.lanzous.com/b01nzf7fc">谷歌浏览器下载 [因为边境墙厚，内地建议…]</a></li><li><a href="https://cit.lanzous.com/b01nzf7li">hosts修改 [建议去github下载最新…]</a></li><li><a href="https://cit.lanzous.com/b01nzf7li">win10超级终端 [win10没有win7的超级…]</a></li><li><a href="https://cit.lanzous.com/b01nzf7pc">win10系统杀手 [慎用！！！]</a></li><li><a href="https://cit.lanzous.com/b01nzf7xa">官网看小插件 [畅享官网看海量资源…]</a></li><li><a href="https://cit.lanzous.com/b01nzf7zc">OCR [一些OCR软件]</a></li><li><a href="https://cit.lanzous.com/b01nzf85i">科大讯飞语音阉割版 [科大讯飞语音阉割版…]</a></li><li><a href="https://cit.lanzous.com/b01nzf89c">微软输入法添加词库 [给微软输入法添加词库…]</a></li><li><a href="https://cit.lanzous.com/b01nzf8dg">DNS优选 [垃圾玩意儿！骗人的吧我…]</a></li><li><a href="https://cit.lanzous.com/b01nzf8ib">win10火绒安全 [建议去官网]</a></li><li><a href="https://cit.lanzous.com/b01nzf8ng">win10系统优化 [Dism++，就建议去官网…]</a></li><li><a href="https://cit.lanzous.com/b01nzf8ra">office安装 [还是建议去亦是美官网…]</a></li><li><a href="https://cit.lanzous.com/b01nzf98h">浏览器清除缓存提高速度 [win版，适用于谷歌、微…]</a></li><li><a href="https://cit.lanzous.com/b01nzf9hg">截屏工具 [一些优秀的截屏工具 s…]</a></li><li><a href="https://cit.lanzous.com/b01nzidfg">网抑云</a></li></ul><h1 id="CITPans（单文件夹-gt-100M）"><a href="#CITPans（单文件夹-gt-100M）" class="headerlink" title="CITPans（单文件夹&gt;100M）"></a><a href="https://citpan.herokuapp.com/">CITPans</a>（单文件夹&gt;100M）</h1><p>点击<a href="https://citpan.herokuapp.com/">CITPans</a>到我搭建的云盘网站吧。。。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这玩意儿花里胡哨的还浪费精力，但还是秉承着互联网分享/共享精神！（之前查了一下百度百科是分享MBA智库百科是共享）</p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud </tag>
            
            <tag> 分享 </tag>
            
            <tag> 共享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python3网络爬虫开发实战教程线上整理</title>
      <link href="2021/01/31/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B%E7%BA%BF%E4%B8%8A%E6%95%B4%E7%90%86/"/>
      <url>2021/01/31/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B%E7%BA%BF%E4%B8%8A%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Python3网络爬虫开发实战教程线上整理"><a href="#Python3网络爬虫开发实战教程线上整理" class="headerlink" title="Python3网络爬虫开发实战教程线上整理"></a>Python3网络爬虫开发实战教程线上整理</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>提起爬虫，Python爬虫界几乎无人不知崔大佬，它的爬虫书——《Python3 网络爬虫开发实战》18年一经出版就非常畅销。书籍质量很高，但爬虫是一种要与反爬不断斗争的技术，很多当时有效的爬虫随着互联网技术的飞速发展现在大多黯然失色，崔大佬本人也因此和拉勾教育合作于20年初推出《52讲轻松搞定网络爬虫》。当然时隔近一年，后者有些部分也显得跟不上时代，期待崔大神新作。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/Python-3%E7%BD%91%E6%A0%BC%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E7%AB%8B%E4%BD%93%E5%9B%BE-857x1100.jpg" alt="img"></p><p>但是还是要说但是了，有些基本知识的精华还是很有价值的，崔大佬无奈书本知识的滞后也偷偷开放付费章节到本人博客但是比较乱，因此这里整理崔庆才博客相关链接，具体内容请点击相应链接跳转到作者博客。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>根据崔大佬的博客在github上，检索关键字获得隐藏链接。</p><h2 id="链接整理"><a href="#链接整理" class="headerlink" title="链接整理"></a>链接整理</h2><ul><li><a href="https://cuiqingcai.com/5054.html">1 - 开发环境配置</a><ul><li><a href="https://cuiqingcai.com/5059.html">1.1-Python3 的安装</a></li><li><a href="https://cuiqingcai.com/5081.html">1.2 - 请求库的安装</a><ul><li><a href="https://cuiqingcai.com/5132.html">1.2.1-Requests 的安装</a></li><li><a href="https://cuiqingcai.com/5141.html">1.2.2-Selenium 的安装</a></li><li><a href="https://cuiqingcai.com/5135.html">1.2.3-ChromeDriver 的安装</a></li><li><a href="https://cuiqingcai.com/5153.html">1.2.4-GeckoDriver 的安装</a></li><li><a href="https://cuiqingcai.com/5159.html">1.2.5-PhantomJS 的安装</a></li><li><a href="https://cuiqingcai.com/5163.html">1.2.6-aiohttp 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5168.html">1.3 - 解析库的安装</a><ul><li><a href="https://cuiqingcai.com/5180.html">1.3.1-lxml 的安装</a></li><li><a href="https://cuiqingcai.com/5183.html">1.3.2-Beautiful Soup 的安装</a></li><li><a href="https://cuiqingcai.com/5186.html">1.3.3-pyquery 的安装</a></li><li><a href="https://cuiqingcai.com/5189.html">1.3.4-tesserocr 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5197.html">1.4 - 数据库的安装</a><ul><li><a href="https://cuiqingcai.com/5200.html">1.4.1-MySQL 的安装</a></li><li><a href="https://cuiqingcai.com/5205.html">1.4.2-MongoDB 安装</a></li><li><a href="https://cuiqingcai.com/5219.html">1.4.3-Redis 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5224.html">1.5 - 存储库的安装</a><ul><li><a href="https://cuiqingcai.com/5227.html">1.5.1-PyMySQL 的安装</a></li><li><a href="https://cuiqingcai.com/5230.html">1.5.2-PyMongo 的安装</a></li><li><a href="https://cuiqingcai.com/5233.html">1.5.3-redis-py 的安装</a></li><li><a href="https://cuiqingcai.com/5236.html">1.5.4-RedisDump 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5239.html">1.6-Web 库的安装</a><ul><li><a href="https://cuiqingcai.com/5244.html">1.6.1-Flask 的安装</a></li><li><a href="https://cuiqingcai.com/5248.html">1.6.2-Tornado 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5252.html">1.7-App 爬取相关库的安装</a><ul><li><a href="https://cuiqingcai.com/5255.html">1.7.1-Charles 的安装</a></li><li><a href="https://cuiqingcai.com/5391.html">1.7.2-mitmproxy 的安装</a></li><li><a href="https://cuiqingcai.com/5407.html">1.7.3-Appium 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5413.html">1.8 - 爬虫框架的安装</a><ul><li><a href="https://cuiqingcai.com/5416.html">1.8.1-pyspider 的安装</a></li><li><a href="https://cuiqingcai.com/5421.html">1.8.2-Scrapy 的安装</a></li><li><a href="https://cuiqingcai.com/5428.html">1.8.3-Scrapy-Splash 的安装</a></li><li><a href="https://cuiqingcai.com/5432.html">1.8.4-Scrapy-Redis 的安装</a></li></ul></li><li><a href="https://cuiqingcai.com/5435.html">1.9 - 部署相关库的安装</a><ul><li><a href="https://cuiqingcai.com/5438.html">1.9.1-Docker 的安装</a></li><li><a href="https://cuiqingcai.com/5445.html">1.9.2-Scrapyd 的安装</a></li><li><a href="https://cuiqingcai.com/5449.html">1.9.3-Scrapyd-Client 的安装</a></li><li><a href="https://cuiqingcai.com/5453.html">1.9.4-Scrapyd API 的安装</a></li><li><a href="https://cuiqingcai.com/5456.html">1.9.5-Scrapyrt 的安装</a></li><li><a href="https://cuiqingcai.com/5459.html">1.9.6-Gerapy 的安装</a></li></ul></li></ul></li><li><a href="https://cuiqingcai.com/5462.html">2 - 爬虫基础</a><ul><li><a href="https://cuiqingcai.com/5465.html">2.1-HTTP 基本原理</a></li><li><a href="https://cuiqingcai.com/5476.html">2.2 - 网页基础</a></li><li><a href="https://cuiqingcai.com/5484.html">2.3 - 爬虫的基本原理</a></li><li><a href="https://cuiqingcai.com/5487.html">2.4 - 会话和 Cookies</a></li><li><a href="https://cuiqingcai.com/5491.html">2.5 - 代理的基本原理</a></li></ul></li><li><a href="https://cuiqingcai.com/5494.html">3 - 基本库的使用</a><ul><li><a href="https://cuiqingcai.com/5497.html">3.1 - 使用 urllib</a><ul><li><a href="https://cuiqingcai.com/5500.html">3.1.1 - 发送请求</a></li><li><a href="https://cuiqingcai.com/5505.html">3.1.2 - 处理异常</a></li><li><a href="https://cuiqingcai.com/5508.html">3.1.3 - 解析链接</a></li><li><a href="https://cuiqingcai.com/5511.html">3.1.4 - 分析 Robots 协议</a></li></ul></li><li><a href="https://cuiqingcai.com/5514.html">3.2 - 使用 requests</a><ul><li><a href="https://cuiqingcai.com/5517.html">3.2.1 - 基本用法</a></li><li><a href="https://cuiqingcai.com/5523.html">3.2.2 - 高级用法</a></li></ul></li><li><a href="https://cuiqingcai.com/5530.html">3.3 - 正则表达式</a></li><li><a href="https://cuiqingcai.com/5534.html">3.4 - 抓取猫眼电影排行</a></li></ul></li><li><a href="https://cuiqingcai.com/5542.html">4 - 解析库的使用</a><ul><li><a href="https://cuiqingcai.com/5545.html">4.1 - 使用 XPath</a></li><li><a href="https://cuiqingcai.com/5548.html">4.2 - 使用 Beautiful Soup</a></li><li><a href="https://cuiqingcai.com/5551.html">4.3 - 使用 pyquery</a></li></ul></li><li><a href="https://cuiqingcai.com/5554.html">5 - 数据存储</a><ul><li><a href="https://cuiqingcai.com/5557.html">5.1 - 文件存储</a><ul><li><a href="https://cuiqingcai.com/5560.html">5.1.1-TXT 文本存储</a></li><li><a href="https://cuiqingcai.com/5564.html">5.1.2-JSON 文件存储</a></li><li><a href="https://cuiqingcai.com/5571.html">5.1.3-CSV 文件存储</a></li></ul></li><li><a href="https://cuiqingcai.com/5575.html">5.2 - 关系型数据库存储</a><ul><li><a href="https://cuiqingcai.com/5578.html">5.2.1-MySQL 存储</a></li></ul></li><li><a href="https://cuiqingcai.com/5581.html">5.3 - 非关系型数据库存储</a><ul><li><a href="https://cuiqingcai.com/5584.html">5.3.1-MongoDB 存储</a></li><li><a href="https://cuiqingcai.com/5587.html">5.3.2-Redis 存储</a></li></ul></li></ul></li><li><a href="https://cuiqingcai.com/5590.html">6-Ajax 数据爬取</a><ul><li><a href="https://cuiqingcai.com/5593.html">6.1 - 什么是 Ajax</a></li><li><a href="https://cuiqingcai.com/5597.html">6.2-Ajax 分析方法</a></li><li><a href="https://cuiqingcai.com/5609.html">6.3-Ajax 结果提取</a></li><li><a href="https://cuiqingcai.com/5616.html">6.4 - 分析 Ajax 爬取今日头条街拍美图</a></li></ul></li><li><a href="https://cuiqingcai.com/5627.html">7 - 动态渲染页面爬取</a><ul><li><a href="https://cuiqingcai.com/5630.html">7.1-Selenium 的使用</a></li><li><a href="https://cuiqingcai.com/5638.html">7.2-Splash 的使用</a></li><li><a href="https://cuiqingcai.com/5654.html">7.3-Splash 负载均衡配置</a></li><li><a href="https://cuiqingcai.com/5657.html">7.4 - 使用 Selenium 爬取淘宝商品</a></li></ul></li><li><a href="hhttps://cuiqingcai.com/7032.html">8 - 验证码的识别</a><ul><li><a href="https://cuiqingcai.com/7035.html">8.1 - 图形验证码的识别</a></li><li><a href="https://cuiqingcai.com/7037.html">8.2 - 极验滑动验证码的识别</a></li><li><a href="https://cuiqingcai.com/7039.html">8.3 - 点触验证码的识别</a></li><li><a href="https://cuiqingcai.com/7041.html">8.4 - 微博宫格验证码的识别</a></li></ul></li><li><a href="https://cuiqingcai.com/7043.html">9 - 代理的使用</a><ul><li><a href="https://cuiqingcai.com/7045.html">9.1 - 代理的设置</a></li><li><a href="https://cuiqingcai.com/7048.html">9.2 - 代理池的维护</a></li><li><a href="https://cuiqingcai.com/7051.html">9.3 - 付费代理的使用</a></li><li><a href="https://cuiqingcai.com/8361.html">9.4-ADSL 拨号代理</a></li><li><a href="https://cuiqingcai.com/7844.html">9.5 - 使用代理爬取微信公众号文章</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">10 - 模拟登录</a><ul><li><a href="https://cuiqingcai.com/8229.html">10.1 - 模拟登录并爬取 GitHub</a></li><li><a href="https://cuiqingcai.com/8243.html">10.2-Cookies 池的搭建</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">11-App 的爬取</a><ul><li><a href="https://cuiqingcai.com/8247.html">11.1-Charles 的使用</a></li><li><a href="https://cuiqingcai.com/8260.html">11.2-mitmproxy 的使用</a></li><li><a href="https://cuiqingcai.com/8263.html">11.3-mitmdump 爬取 “得到” App 电子书信息</a></li><li><a href="https://cuiqingcai.com/8290.html">11.4-Appium 的基本使用</a></li><li><a href="https://cuiqingcai.com/8293.html">11.5-Appium 爬取微信朋友圈</a></li><li><a href="https://cuiqingcai.com/8306.html">11.6-Appium+mitmdump 爬取京东商品</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">12-pyspider 框架的使用</a><ul><li><a href="https://cuiqingcai.com/8309.html">12.1-pyspider 框架介绍</a></li><li><a href="https://cuiqingcai.com/8317.html">12.2-pyspider 的基本使用</a></li><li><a href="https://cuiqingcai.com/8320.html">12.3-pyspider 用法详解</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">13-Scrapy 框架的使用</a><ul><li><a href="https://cuiqingcai.com/8364.html">13.1-Scrapy 框架介绍</a></li><li><a href="https://cuiqingcai.com/8337.html">13.2-Scrapy 入门</a></li><li><a href="https://cuiqingcai.com/8350.html">13.3-Selector 的用法</a></li><li><a href="https://cuiqingcai.com/8353.html">13.4-Spider 的用法</a></li><li><a href="https://cuiqingcai.com/8381.html">13.5-Downloader Middleware 的用法</a></li><li><a href="https://cuiqingcai.com/8385.html">13.6-Spider Middleware 的用法</a></li><li><a href="https://cuiqingcai.com/8394.html">13.7-Item Pipeline 的用法</a></li><li><a href="https://cuiqingcai.com/8397.html">13.8-Scrapy 对接 Selenium</a></li><li><a href="https://cuiqingcai.com/8410.html">13.9-Scrapy 对接 Splash</a></li><li><a href="https://cuiqingcai.com/8413.html">13.10-Scrapy 通用爬虫</a></li><li><a href="https://cuiqingcai.com/8445.html">13.11-Scrapyrt 的使用</a></li><li><a href="https://cuiqingcai.com/8448.html">13.12-Scrapy 对接 Docker</a></li><li><a href="https://cuiqingcai.com/8453.html">13.13-Scrapy 爬取新浪微博</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">14 - 分布式爬虫</a><ul><li><a href="https://cuiqingcai.com/8456.html">14.1 - 分布式爬虫原理</a></li><li><a href="https://cuiqingcai.com/8465.html">14.2-Scrapy-Redis 源码解析</a></li><li><a href="https://cuiqingcai.com/8468.html">14.3-Scrapy 分布式实现</a></li><li><a href="https://cuiqingcai.com/8472.html">14.4-Bloom Filter 的对接</a></li></ul></li><li><a href="https://cuiqingcai.com/5678.html">15 - 分布式爬虫的部署</a><ul><li><a href="https://cuiqingcai.com/8475.html">15.1-Scrapyd 分布式部署</a></li><li><a href="https://cuiqingcai.com/8491.html">15.2-Scrapyd-Client 的使用</a></li><li><a href="https://cuiqingcai.com/8494.html">15.3-Scrapyd 对接 Docker</a></li><li><a href="https://cuiqingcai.com/8506.html">15.4-Scrapyd 批量部署</a></li><li><a href="https://cuiqingcai.com/8509.html">15.5-Gerapy 分布式管理</a></li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>18年的知识有些是精华，但有些失效的部分就需要擦亮双眼分辨一下。</p><p>这里还推荐一下<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=46#/content">《52讲轻松搞定网络爬虫》</a>以前新用户1元白嫖任意一门课，现在好像是7天VIP会员——好像督促你7天把他学完！！！关于这个我也有一些<a href="https://github.com/Kit139/52scrapy">学习笔记</a>，当然copy+修修补补有些地方可能与崔大佬不一样，但也是可以看看的。</p><p>参考：</p><ul><li><a href="https://github.com/Germey/Blog">崔庆才博客在github的源码</a></li><li><a href="https://cuiqingcai.com/5052.html">Python3 网络爬虫开发实战教程</a>目录中13.5及以后后会跳转到购买书籍章节</li></ul>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20210124CITPython交流+WebScraper可视化爬虫</title>
      <link href="2021/01/24/20210124CITPython%E4%BA%A4%E6%B5%81+WebScraper%E5%8F%AF%E8%A7%86%E5%8C%96%E7%88%AC%E8%99%AB/"/>
      <url>2021/01/24/20210124CITPython%E4%BA%A4%E6%B5%81+WebScraper%E5%8F%AF%E8%A7%86%E5%8C%96%E7%88%AC%E8%99%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="20210124CITPython交流-WebScraper可视化爬虫"><a href="#20210124CITPython交流-WebScraper可视化爬虫" class="headerlink" title="20210124CITPython交流+WebScraper可视化爬虫"></a>20210124CITPython交流+WebScraper可视化爬虫</h1><h2 id="可视化爬虫"><a href="#可视化爬虫" class="headerlink" title="可视化爬虫"></a>可视化爬虫</h2><p>为什么叫可视化爬虫？（当然这里本人承认自己略有根据地随意起的哈哈哈哈哈哈）</p><ul><li><p>本教程可面向纯小白用户，不写代码不写公式，迈出数据分析的第一步。</p></li><li><p>这些操作几乎全部都是GUI可视化界面的操作，当然有点网页结构、爬虫思维更好。</p></li><li><p>生活中很多的数据分析场合，都是很轻量的，不需要上 Python 爬虫、高并发架构，机器学习等重武器，一个浏览器再加一个 Excel 就足够了：</p><p>比如说某门课程论文交稿只有几天了，急需快速爬取数据进行数据分析，这时候临阵磨枪学习 Python 爬虫知识时间完全不够；<br>做一些市场调研和运营工作需要对数据进行采集，让技术部门支持的话，走流程的周期过长，不如撸起袖子自己做；<br>工作跳槽，想知道市场上的技能要求和薪资分布，需要采集数据并分析市场需求；<br>……<br>这些都是生活中会遇到的问题，面对这些数据量不大（100~10000）的分析需求，非互联网技术人士去学习一些编程知识其实性价比并不高。我们不如利用手头最常见的工具——Excel 和 浏览器，去分析去梳理数据，辅助进行思考和更好的决策。</p></li></ul><p>这也算本门教程的目的——用 20% 的精力解决 80% 的数据分析需求，解放个人的生产力。</p><p>爬虫，即数据采集，就是利用爬虫软件从互联网上爬取想要数据，然后存储到本地；简单的可以使用Excel、WebScraper、八爪鱼等，今天我们以WebScraper为例，因为在我眼里，小组的人Excel爬虫都会点儿，而八爪鱼采集器≈浏览器+插件WebScraper！！！</p><p>而且WebScraper还有以下有点：</p><ol><li>门槛足够低，只要你电脑上安装了 Chrome 浏览器就可以用</li><li>永久免费，无付费功能，无需注册</li><li>操作简单，点几次鼠标就能爬取网页，真正意义上的 0 行代码写爬虫</li></ol><h2 id="WebScraper安装"><a href="#WebScraper安装" class="headerlink" title="WebScraper安装"></a>WebScraper安装</h2><p>会科学上网的请点击谷歌商店搜索WebScraper关键词，<a href="https://chrome.google.com/webstore/detail/web-scraper-free-web-scra/jnhgnonknehpejjnehehllkliplmbmhn?hl=zh-CN">直达通道</a></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62402899.webp" alt="img"></p><p>也可到国内一些类似谷歌商店的镜像，如<a href="https://chrome.zzzmh.cn/">极简插件</a>、<a href="https://www.extfans.com/">扩展密</a>、<a href="https://www.gugeapps.net/">仿chrome 网上应用店</a>等，但因为非官方能科学上网的还是不太建议</p><h2 id="爬取一页"><a href="#爬取一页" class="headerlink" title="爬取一页"></a>爬取一页</h2><p>但凡做爬虫练手，第一个爬取的网站一般都是<a href="https://movie.douban.com/top250?start=0&filter=">豆瓣电影 TOP 250</a>，网址链接是 <a href="https://movie.douban.com/top250?start=0&amp;filter=%E3%80%82%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%8A%E6%89%8B%EF%BC%8C%E6%88%91%E4%BB%AC%E7%88%AC%E5%8F%96%E7%9A%84%E5%86%85%E5%AE%B9%E5%B0%BD%E9%87%8F%E7%AE%80%E5%8D%95%EF%BC%8C%E6%89%80%E4%BB%A5%E6%88%91%E4%BB%AC%E5%8F%AA%E7%88%AC%E5%8F%96%E7%AC%AC%E4%B8%80%E9%A1%B5%E7%9A%84%E7%94%B5%E5%BD%B1%E6%A0%87%E9%A2%98%E3%80%82">https://movie.douban.com/top250?start=0&amp;filter=。第一次上手，我们爬取的内容尽量简单，所以我们只爬取第一页的电影标题。</a></p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697176.webp" alt="img"></p><p>浏览器按 <code>F12</code> 打开控制台，并把控制台放在网页的<strong>下方</strong>（具体操作可以看<a href="https://www.cnblogs.com/web-scraper/p/web_scraper_start_2.html">上一篇文章</a>），然后找到 Web Scraper 这个 Tab，点进去就来到了 Web Scraper 的控制页面。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697178.webp" alt="img"></p><p>进入 Web Scraper 的控制页面后，我们按照 <code>Create new sitemap</code> -&gt; <code>Create Sitemap</code> 的操作路径，创建一个新的爬虫，<code>sitemap</code> 是啥意思并不重要，你就当他是个爬虫的别名就好了。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697177.webp" alt="img"></p><p>我们在接下来出现的输入框里依次输入爬虫名和要爬取的链接。</p><p>爬虫名可能会有字符类型的限制，我们看一下规则规避就好了，最后点击 <code>Create Sitemap</code> 这个按钮，创建我们的第一个爬虫。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697181.webp" alt="img"></p><p>这时候会跳到一个新的操作面板，不要管别的，我们直接点击 <code>Add new selector</code> 这个蓝底白字的按钮，顾名思义，创建一个选择器，用来选择我们想要抓取的元素。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697180.webp" alt="img"></p><p>这时候就要开始正式的数据抓取环节了！我们先观察一下这个面板有些什么东西：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697183.webp" alt="img"></p><blockquote><p>1.首先有个 Id，这个就是给我们要爬取的内容标注一个 id，因为我们要抓取电影的名字，简单起见就取个 name 吧； 2.电影名字很明显是一段文字，所以 Type 类型肯定是 Text，在这个爬虫工具里，默认 Type 类型就是 Text，这次的爬取工作就不需要改动了； 3.我们把多选按钮 Multiple 勾选上，因为我们要抓的是批量的数据，不勾选的话只能抓取一个； 4.最后我们点击黄色圆圈里的 Select，开始在网页上勾选电影名字；</p></blockquote><p>当你把鼠标移动到网页时，会发现网页上出现了绿色的方块儿，这些方块就是网页的构成元素，当我们点击鼠标时，绿色的方块儿就会变为红色，表示这个元素被选中了：</p><p><img src="https://img2.doubanio.com/view/note/l/public/p62697182.webp" alt="img"></p><p>这时候我们就可以进行我们的抓取工作了。</p><p>我们先选择「<strong>肖生克的救赎</strong>」这个标题，然后再选择「<strong>霸王别姬</strong>」这个标题（<strong>注意：想达到多选的效果，一定要手动选取两个以上的内容</strong>）</p><p>选完这两个标题后，向下拉动网页，你就会发现所有的电影名字都被选中了：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697185.webp" alt="img"></p><p>拉动网页检查一遍，发现所有的电影标题都被选中后，我们就可以点击 <code>Done selecting!</code>这个按钮，表示选择完毕；</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697184.webp" alt="img"></p><p>点击按钮后你会发现下图的红框位置会出现了一些字符，一般出现这个就表示选取成功了：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697186.webp" alt="img"></p><p>我们点击 <code>Data preview</code> 这个按钮，就可以预览我们的抓取效果了：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697187.webp" alt="img"></p><p>没什么问题的话，关闭 Data Preview 弹窗，翻到面板的最下面，有个 <code>Save selector</code> 的蓝色按钮，点击后我们会回退到上一个面板。</p><p>这时候你会发现多了一行数据，其实就是我们刚刚的操作内容被记录下来了。</p><p>在顶部的 tab 栏，有一个 <code>Sitemap top250</code> 的 tab，这个就是我们刚刚创建的爬虫。点击它，再点击下拉菜单里的 <code>Scrape</code> 按钮，开始我们的数据抓取。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697188.webp" alt="img"></p><p>这时候你会跳到另一个面板，里面有两个输入框，先别管他们是什么，全部输入 2000 就好了。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697189.webp" alt="img"></p><p>点击 <code>Start scraping</code> 蓝色按钮后，会跳出一个新的网页，<code>Web Scraper</code> 插件会在这里进行数据抓取：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697191.webp" alt="img"></p><p>一般弹出的网页自动关闭就代表着数据抓取结束了，我们点击面板上的 <code>refresh</code> 蓝色按钮，就可以看到我们抓取的数据了！</p><p>在这个预览面板上，第一列是 web scraper 自动添加的编号，没啥意义；第二列是抓取的链接，第三列就是我们抓取的数据了。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697190.webp" alt="img"></p><p>这个数据会存储在我们的浏览器里，我们也可以点击 <code>Sitemap top250</code> 下的 <code>Export data as CSV</code>，这样就可以导出成 <code>.csv</code> 格式的数据，这种格式可以用 Excel 打开，我们可以用 Excel 做一些数据格式化的操作。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697192.webp" alt="img"></p><p>接下来我们分析一下网页进行翻页（其实爬虫第一步应该是先分析网页来着哈哈哈哈哈哈哈）</p><h2 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h2><p>我们先看看第一页的豆瓣网址链接：</p><blockquote><p><a href="https://movie.douban.com/top250?start=0&amp;filter=">https://movie.douban.com/top250?start=0&amp;filter=</a></p></blockquote><ol><li><code>https://movie.douban.com</code> 这个很明显就是个豆瓣的电影网址，没啥好说的</li><li><code>top250</code> 这个一看就是网页的内容，豆瓣排名前 250 的电影，也没啥好说的</li><li><code>?</code> 后面有个<code>start=0&amp;filter=</code> ，根据英语提示来看，好像是说筛选（filter），从 0 开始（start）</li></ol><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890353.webp" alt="img"></p><p>再看看第二页的网址链接，前面都一样，只有后面的参数变了，变成了 <code>start=25</code>，从 25 开始；</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890355.webp" alt="img"></p><p>我们再看看第三页的链接，参数变成了  <code>start=50</code>，从 50 开始；</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890356.webp" alt="img"></p><p>分析 3 个链接我们很容易得出规律：</p><blockquote><p>start=0，表示从排名第 1 的电影算起，展示 1-25 的电影 start=25，表示从排名第 26 的电影算起，展示 26-50 的电影 start=50，表示从排名第 51 的电影算起，展示 51-75 的电影 …… start=225，表示从排名第 226 的电影算起，展示 226-250 的电影</p></blockquote><p>规律找到了就好办了，只要技术提供支持就行。<strong>随着深入学习，你会发现 Web Scraper 的操作并不是难点，最需要思考的其实还是这个找规律。</strong></p><p>Web Scraper 针对这种通过<strong>超链接数字分页</strong>获取分页数据的网页，提供了非常便捷的操作，那就是<strong>范围指定器</strong>。</p><p>比如说你想抓取的网页链接是这样的：</p><ul><li><code>http://example.com/page/1</code></li><li><code>http://example.com/page/2</code></li><li><code>http://example.com/page/3</code></li></ul><p>你就可以写成 <a href="http://example.com/page/[1-3]%EF%BC%8C%E6%8A%8A%E9%93%BE%E6%8E%A5%E6%94%B9%E6%88%90%E8%BF%99%E6%A0%B7%EF%BC%8CWeb">http://example.com/page/[1-3]，把链接改成这样，Web</a> Scraper 就会自动抓取这三个网页的内容。</p><p>当然，你也可以写成 <a href="http://example.com/page/[1-100]%EF%BC%8C%E8%BF%99%E6%A0%B7%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%93%E5%8F%96%E5%89%8D">http://example.com/page/[1-100]，这样就可以抓取前</a> 100 个网页。</p><p>那么像我们之前分析的豆瓣网页呢？它不是从 1 到 100 递增的，而是 0 -&gt; 25 -&gt; 50 -&gt; 75 这样每隔 25 跳的，这种怎么办？</p><ul><li><code>http://example.com/page/0</code></li><li><code>http://example.com/page/25</code></li><li><code>http://example.com/page/50</code></li></ul><p>其实也很简单，这种情况可以用 <code>[0-100:25]</code> 表示，每隔 25 是一个网页，100/25=4，爬取前 4 个网页，放在豆瓣电影的情景下，我们只要把链接改成下面的样子就行了；</p><p><a href="https://movie.douban.com/top250?start=%5B0-225:25%5D&amp;filter=">https://movie.douban.com/top250?start=[0-225:25]&amp;filter=</a></p><p>这样 Web Scraper 就会抓取 TOP250 的所有网页了。</p><h2 id="翻页爬取"><a href="#翻页爬取" class="headerlink" title="翻页爬取"></a>翻页爬取</h2><p>解决了链接的问题，接下来就是如何在 Web Scraper 里修改链接了，很简单，就点击两下鼠标：</p><p>**1.**点击 <code>Stiemaps</code>，在新的面板里点击 ID 为 <code>top250</code> 的这列数据；</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890357.webp" alt="img"></p><p>**2.**进入新的面板后，找到 <code>Stiemap top250</code> 这个 Tab，点击，再点击下拉菜单里的 <code>Edit metadata</code>；</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890358.webp" alt="img"></p><p>**3.**修改原来的网址，图中的红框是不同之处：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890359.webp" alt="img"></p><p>修改好了超链接，我们重新抓取网页就好了。操作和<a href="https://www.cnblogs.com/web-scraper/p/web_scraper_first_scrape_douban.html">上文</a>一样，我这里就简单复述一下：</p><ol><li>点击 <code>Sitemap top250</code> 下拉菜单里的 <code>Scrape</code> 按钮</li><li>新的操作面板的两个输入框都输入 2000</li><li>点击 <code>Start scraping</code> 蓝色按钮开始抓取数据</li><li>抓取结束后点击面板上的 <code>refresh</code> 蓝色按钮，检测我们抓取的数据</li></ol><p>如果你操作到这里并抓取成功的话，你会发现数据是全部抓取下来了，但是顺序都是乱的。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/p62890360.webp" alt="img"></p><p>我们这里先不管顺序问题，因为这个属于<strong>数据清洗</strong>的内容了，我们现在的专题是<strong>数据抓取</strong>。先把相关的知识点讲完，再攻克下一个知识点，才是更合理的学习方式。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来说，WebScraper相较于Python门槛更低、更易上手，但上限有限，也希望WebScraper社区不断改进。</p><p>但是还是要说但是了，这种自动化爬虫对于我们来说日常采集数据的需求还是够用一些了。</p><iframe id="pqvE7xEK-1596373719908" src="https://citpan.herokuapp.com/CITpan/CIT%E5%B0%8F%E7%BB%84%E8%B5%84%E6%BA%90/CIT%E5%9F%B9%E8%AE%AD%E5%9B%9E%E6%94%BE/20210124CITPython%E4%BA%A4%E6%B5%81%2BWebScraper%E5%8F%AF%E8%A7%86%E5%8C%96%E7%88%AC%E8%99%AB.mp4?preview" allowfullscreen="true" data-mediaembed="bilibili" __idm_id__="291592193" style="box-sizing: border-box; outline: 0px; margin: 0px; padding: 0px; font-weight: normal; overflow-wrap: break-word; display: block; width: 660px; height: 330px;"></iframe><p>这个插入的视频好像有点问题，去B站吧-&gt;<a href="https://www.bilibili.com/video/BV1d54y1s7hZ">回放</a>与<a href="https://github.com/Kit139/WebScraper">代码</a>献上</p><p>参考文献：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/88193090">不会写Python代码如何抓取豆瓣电影 Top 250</a></li><li><a href="https://www.douban.com/note/724882625">简易数据分析 04 | Web Scraper 初尝–抓取豆瓣高分电影</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> CIT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> WebScraper </tag>
            
            <tag> 自动化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pandas网页Table表格型数据爬虫+快代理实战</title>
      <link href="2021/01/17/Pandas%E7%BD%91%E9%A1%B5Table%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB+%E5%BF%AB%E4%BB%A3%E7%90%86%E5%AE%9E%E6%88%98/"/>
      <url>2021/01/17/Pandas%E7%BD%91%E9%A1%B5Table%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB+%E5%BF%AB%E4%BB%A3%E7%90%86%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Pandas网页Table表格型数据爬虫-快代理实战"><a href="#Pandas网页Table表格型数据爬虫-快代理实战" class="headerlink" title="Pandas网页Table表格型数据爬虫+快代理实战"></a>Pandas网页Table表格型数据爬虫+快代理实战</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>听说有些刚入门的觉得上次的requests爬虫有点难度？那咱们就来个更简单的——pandas爬虫，虽然它很鸡肋。。。</p><p>优点：对于网页的抓取Table表格型数据专能，代码几行代码就能爬下数据，适合入门</p><p>缺点：用途单一，你想要的数据怎么可能都在表格里呢。。。学着玩玩留作备用吧哈哈哈哈哈哈哈</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20210117180027.png"></p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>pandas是基于NumPy 的一种工具，该工具是为解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。本次使用pandas中的pd.read_html()这个函数，功能非常强大，可以轻松实现抓取Table表格型数据。无需掌握正则表达式或者xpath等工具，短短的几行代码就可以将网页数据抓取下来。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="1-Table表格型数据网页结构"><a href="#1-Table表格型数据网页结构" class="headerlink" title="1.Table表格型数据网页结构"></a>1.Table表格型数据网页结构</h3><p>pandas适合抓取Table表格型数据，那么咱们首先得知道什么样的网页具有Table表格型数据结构(有html基础的大佬可自行跳过这一part)。</p><p>我们先来看个简单的例子。（快捷键F12可快速查看网页的HTML结构）</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210117220259618.png" alt="image-20210117220259618"></p><p>从以上网站可以看出，数据存储在一个table表格中，thread为表头，tbody为表格数据，tbody中的一个tr对应表中的一行，一个td对应一个表中元素。</p><p>我们再来看一个例子：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/hn2vzm93rz.png" alt="hn2vzm93rz"></p><p>也许你已经发现了规律，以Table结构展示的表格数据，大致的网页结构如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;table class=&quot;...&quot; id=&quot;...&quot;&gt;</span><br><span class="line">     &lt;thead&gt;</span><br><span class="line">     &lt;tr&gt;</span><br><span class="line">     &lt;th&gt;...&lt;/th&gt;</span><br><span class="line">     &lt;/tr&gt;</span><br><span class="line">     &lt;/thead&gt;</span><br><span class="line">     &lt;tbody&gt;</span><br><span class="line">        &lt;tr&gt;</span><br><span class="line">            &lt;td&gt;...&lt;/td&gt;</span><br><span class="line">        &lt;/tr&gt;</span><br><span class="line">        &lt;tr&gt;...&lt;/tr&gt;</span><br><span class="line">        &lt;tr&gt;...&lt;/tr&gt;</span><br><span class="line">        ...</span><br><span class="line">        &lt;tr&gt;...&lt;/tr&gt;</span><br><span class="line">        &lt;tr&gt;...&lt;/tr&gt;        </span><br><span class="line">    &lt;/tbody&gt;</span><br><span class="line">&lt;/table&gt;</span><br></pre></td></tr></table></figure><p>只要网页具有以上结构，你就可以尝试用pandas抓取数据。</p><h3 id="2-pandas请求表格数据流程"><a href="#2-pandas请求表格数据流程" class="headerlink" title="2.pandas请求表格数据流程"></a>2.pandas请求表格数据流程</h3><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210117185828682.png" alt="流程图"></p><p>针对网页结构类似的表格类型数据，pd.read_html()可以将网页上的表格数据都抓取下来，并以DataFrame的形式装在一个list中返回。</p><h3 id="3-pd-read-html语法及参数"><a href="#3-pd-read-html语法及参数" class="headerlink" title="3.pd.read_html语法及参数"></a>3.pd.read_html语法及参数</h3><p>（1）<strong>基本语法</strong>：</p><p>pycharm快捷键可以看到read_html()的参数</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210117182126073.png" alt="image-20210117182126073"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pandas.read_html(io,match=<span class="string">&#x27;.+&#x27;</span>,flavor=<span class="literal">None</span>,header=<span class="literal">None</span>,index_col=<span class="literal">None</span>,skiprows=<span class="literal">None</span>, attrs=<span class="literal">None</span>,</span><br><span class="line">parse_dates=<span class="literal">False</span>, thousands=<span class="string">&#x27;, &#x27;</span>, encoding=<span class="literal">None</span>, decimal=<span class="string">&#x27;.&#x27;</span>, converters=<span class="literal">None</span>, na_values=<span class="literal">None</span>, </span><br><span class="line">keep_default_na=<span class="literal">True</span>, displayed_only=<span class="literal">True</span>）</span><br></pre></td></tr></table></figure><p>（2）<strong>主要参数</strong>：</p><table><thead><tr><th>参数</th><th>释义</th></tr></thead><tbody><tr><td>io</td><td>接收网址、文件、字符串</td></tr><tr><td>parse_dates</td><td>解析日期</td></tr><tr><td>flavor</td><td>解析器</td></tr><tr><td>header</td><td>标题行</td></tr><tr><td>skiprows</td><td>跳过的行属性，比如 attrs = {‘id’: ‘table’}</td></tr></tbody></table><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="案例1：抓取世界大学排名"><a href="#案例1：抓取世界大学排名" class="headerlink" title="案例1：抓取世界大学排名"></a>案例1：抓取世界大学排名</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">url1 = <span class="string">&#x27;http://www.compassedu.hk/qs&#x27;</span></span><br><span class="line">df1 = pd.read_html(url1)[<span class="number">0</span>]  <span class="comment">#0表示网页中的第一个Table</span></span><br><span class="line">df1.to_csv(<span class="string">&#x27;世界大学综合排名.csv&#x27;</span>,index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>没错，5行代码，几秒钟就搞定，我们来预览下爬取到的数据：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/24171048-3c6ae3eff36aecb7.png" alt="img"></p><h3 id="案例2：抓取新浪财经基金重仓股数据"><a href="#案例2：抓取新浪财经基金重仓股数据" class="headerlink" title="案例2：抓取新浪财经基金重仓股数据"></a>案例2：抓取新浪财经基金重仓股数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">df2 = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    url2 = <span class="string">&#x27;http://vip.stock.finance.sina.com.cn/q/go.php/vComStockHold/kind/jjzc/index.phtml?p=&#123;page&#125;&#x27;</span>.<span class="built_in">format</span>(page=i+<span class="number">1</span>)</span><br><span class="line">    df2 = pd.concat([df2,pd.read_html(url2)[<span class="number">0</span>]])</span><br><span class="line">    print(<span class="string">&#x27;第&#123;page&#125;页抓取完成&#x27;</span>.<span class="built_in">format</span>(page = i + <span class="number">1</span>))</span><br><span class="line">df2.to_csv(<span class="string">&#x27;./新浪财经数据.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>,index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>没错，8行代码搞定，还是那么简单。如果对翻页爬虫不理解，可查看公众号「菜J学Python」历史原创文章「实战|手把手教你用Python爬虫(附详细源码)」，如果对DataFrame合并不理解，可查看公众号历史原创文章「基础|Pandas常用知识点汇总(四)」。</p><p>我们来预览下爬取到的数据：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/24171048-b5db3843aae2256d.png" alt="img"></p><h3 id="案例3：抓取证监会披露的IPO数据"><a href="#案例3：抓取证监会披露的IPO数据" class="headerlink" title="案例3：抓取证监会披露的IPO数据"></a>案例3：抓取证监会披露的IPO数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time() <span class="comment">#程序计时</span></span><br><span class="line">df3 = DataFrame(data=<span class="literal">None</span>,columns=[<span class="string">&#x27;公司名称&#x27;</span>,<span class="string">&#x27;披露类型&#x27;</span>,<span class="string">&#x27;上市板块&#x27;</span>,<span class="string">&#x27;保荐机构&#x27;</span>,<span class="string">&#x27;披露时间&#x27;</span>, <span class="string">&#x27;公告&#x27;</span>]) <span class="comment">#添加列名</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">3</span>):</span><br><span class="line">    url3 =<span class="string">&#x27;http://eid.csrc.gov.cn/ipo/1010/index_%s.html&#x27;</span>%<span class="built_in">str</span>(i)</span><br><span class="line">    print(url3)</span><br><span class="line">    df3_1 = pd.read_html(url3,encoding=<span class="string">&#x27;utf-8&#x27;</span>)[<span class="number">0</span>]  <span class="comment">#必须加utf-8，否则乱码</span></span><br><span class="line">    df3_1.columns=[<span class="string">&#x27;公司名称&#x27;</span>,<span class="string">&#x27;披露类型&#x27;</span>,<span class="string">&#x27;上市板块&#x27;</span>,<span class="string">&#x27;保荐机构&#x27;</span>,<span class="string">&#x27;披露时间&#x27;</span>, <span class="string">&#x27;公告&#x27;</span>] <span class="comment">#新的df添加列名</span></span><br><span class="line">    df3 = pd.concat([df3,df3_1])  <span class="comment">#数据合并</span></span><br><span class="line">    print(<span class="string">&#x27;第&#123;page&#125;页抓取完成&#x27;</span>.<span class="built_in">format</span>(page=i))</span><br><span class="line"><span class="comment"># df3.to_csv(&#x27;./上市公司IPO信息.csv&#x27;, encoding=&#x27;utf-8&#x27;,index=0) #保存数据到csv文件</span></span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;共抓取&#x27;</span>,<span class="built_in">len</span>(df3),<span class="string">&#x27;家公司,&#x27;</span> + <span class="string">&#x27;用时&#x27;</span>,<span class="built_in">round</span>((end-start)/<span class="number">60</span>,<span class="number">2</span>),<span class="string">&#x27;分钟&#x27;</span>)</span><br><span class="line">print(df3)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210117222007162.png" alt="image-20210117222007162"></p><p>这里只爬取了两页，当然你将range里改一下就能爬取全部页数了，可能需要time.sleep()一下哈哈哈哈哈哈。另外可以发现添加了个程序计时，方便查看爬取速度。</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/24171048-fe0161c35ad75967.png" alt="img"></p><p>2分14秒爬下217页4334条数据，相当nice了。我们来预览下爬取到的数据：</p><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/24171048-9c753186a310ef20.png" alt="img"></p><p>需要注意的是，并不是所有表格都可以用pd.read_html爬取，有的网站表面上看起来是表格，但在网页源代码中不是table格式，而是list列表格式。还有一种情况是网页前后端分离时，你就要XHR或者JS分析了哈哈哈哈哈哈哈</p><h3 id="案例4：快代理"><a href="#案例4：快代理" class="headerlink" title="案例4：快代理"></a>案例4：快代理</h3><p>见视频<a href="https://www.bilibili.com/video/BV15K4y1W7KX/">回放</a></p><p>演示代码见<a href="https://github.com/Kit139/Pandas.read_html">github</a>上</p><p>tips：</p><blockquote><p>小马哥：你们回去都下载下来试试哈，这东西还挺好玩的</p><p>哈哈哈哈哈哈哈还不赶快去下载eNSP学<a href="https://www.bilibili.com/video/BV1Dr4y1T7Co/">网络基础</a>去</p></blockquote><p>参考文章：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/122361747">天秀！Pandas还能用来写爬虫？</a></li><li><a href="https://www.jianshu.com/p/ecb4b2fc7f81">Pandas也能爬虫，还如此简单！</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> Pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python爬取股吧评论+情感分析</title>
      <link href="2021/01/15/Python%E7%88%AC%E5%8F%96%E8%82%A1%E5%90%A7%E8%AF%84%E8%AE%BA+%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
      <url>2021/01/15/Python%E7%88%AC%E5%8F%96%E8%82%A1%E5%90%A7%E8%AF%84%E8%AE%BA+%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="Python爬取股吧评论-情感分析"><a href="#Python爬取股吧评论-情感分析" class="headerlink" title="Python爬取股吧评论+情感分析"></a>Python爬取股吧评论+情感分析</h2><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>上学期老师就让我爬取东方财富股吧评论进行情感打分了，这里总结一下。</p><p>这里只弄简单的，实际短时间爬取海量数据还要买代理。。。 </p><h2 id="2-爬取工具"><a href="#2-爬取工具" class="headerlink" title="2. 爬取工具"></a>2. 爬取工具</h2><p>本文使用了 Python 的 <code>request</code> 库作为主要爬取工具，并且该库具有简单易用等特点，能够满足一般的数据爬取需求。</p><p>进一步，本文使用了 <code>xpath</code> 来获取特定标签所储存的信息。<code>XPath</code>，全称 XML Path Language，即 XML 路径语言。<code>XPath</code> 最初设计是用来搜寻 XML 文档的，但是也同样适用于 HTML 文档的搜索。XPath 的选择功能十分强大，不但提供了非常简洁明了的路径选择表达式，而且还提供了超过 100 个内建函数用于字符串、数值、时间的匹配，以及节点、序列的处理等。甚至，我们可以认为几乎所有定位的节点都可以用 <code>XPath</code> 来选择。</p><p> </p><h2 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3. 代码实现"></a>3. 代码实现</h2><p>本文爬取的股吧为上证指数，作为国民关注度最高的指数，该股吧也是众多的股吧中活跃度最高的。因此用上证指数股吧，作为爬取对象。</p><p>在本文中，我们将仅以「上证指数」的股吧评论为例进行演示。</p><h3 id="3-1-导入相关库"><a href="#3-1-导入相关库" class="headerlink" title="3.1 导入相关库"></a>3.1 导入相关库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import requests         ##获取网页  </span><br><span class="line">from lxml import etree  ##解析文档  </span><br><span class="line">import pandas as pd     ##保存文件  </span><br></pre></td></tr></table></figure><h3 id="3-2-分析网址规律"><a href="#3-2-分析网址规律" class="headerlink" title="3.2 分析网址规律"></a>3.2 分析网址规律</h3><p>网址：<a href="http://guba.eastmoney.com/list,zssh000001,f.html">http://guba.eastmoney.com/list,zssh000001,f.html</a></p><p>第一页如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/640" alt="img"></p><p>第二页如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/guba1.webp" alt="img"></p><p>可以发现，两页网址区别在于 f_ 后面的数字不同，因此可以通过设置数字爬取不同页面内容。</p><h3 id="3-3-爬取和解析网页源代码"><a href="#3-3-爬取和解析网页源代码" class="headerlink" title="3.3 爬取和解析网页源代码"></a>3.3 爬取和解析网页源代码</h3><p><strong>获取 User-Agent</strong></p><p>请求头反爬很常见，尤其是User-Agent现在已是爬虫必备：User-Agent会告诉网站服务器，访问者是通过什么工具来请求的，如果是爬虫请求，一般会拒绝，如果是用户浏览器，就会应答。</p><p>进入开发者模型，点击 Network，如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/guba2.png" alt="img"></p><p>然后，点击任意一个 Name 列的标题，就可以看到 <strong>User-Agent</strong>，如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/6g435uba4.png" alt="img"></p><p>通过 <code>requests</code> 库，我们可以获取网页源代码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;85.0.4183.102 Safari&#x2F;537.36&#39;&#125;  #构造头文件，模拟浏览器。</span><br><span class="line">for page in range(1,max_page+1):</span><br><span class="line">    #获取网页源代码</span><br><span class="line">    print(&#39;crawling the page is &#123;&#125;&#39;.format(page))  </span><br><span class="line">    url&#x3D; f&#39;http:&#x2F;&#x2F;guba.eastmoney.com&#x2F;list,zssh000001,f_&#123;page&#125;.html&#39;  </span><br><span class="line">    response  &#x3D; requests.get(url, headers&#x3D;headers) </span><br></pre></td></tr></table></figure><p>然后，通过 <code>xpath</code> 解析网页源代码，我们就可以获取需要信息。</p><p>在谷歌浏览器内按 F12 进入开发者模型，审查我们所需要的元素，如下图:</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/dhuih.png" alt="img"></p><p>可以看出，所有的标题和时间都保存在属性为 <code>articleh normal_post</code> 的 <code>div</code> 标签下，因此我们可以构造如下代码进行爬取。当然，以上过程也可以借助 <code>XPath Helper</code> 工具大大简化，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">title &#x3D; root.xpath(&quot;&#x2F;&#x2F;div[contains(@class,&#39;articleh normal_post&#39;)]&#x2F;&#x2F;span[@class&#x3D;&#39;l3 a3&#39;]&#x2F;&#x2F;a&#x2F;&#x2F;text()&quot;)  </span><br><span class="line">time &#x3D; root.xpath(&quot;&#x2F;&#x2F;div[contains(@class,&#39;articleh normal_post&#39;)]&#x2F;&#x2F;span[@class&#x3D;&#39;l5 a5&#39;]&#x2F;&#x2F;text()&quot;)  </span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">max_page  &#x3D; 20   #最大爬取页面</span><br><span class="line">all_title &#x3D; []   #爬取的标题存储列表</span><br><span class="line">all_time  &#x3D; []   #爬取的发表时间储存列表</span><br><span class="line">headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;85.0.4183.102 Safari&#x2F;537.36&#39;&#125;  #构造头文件，模拟浏览器。</span><br><span class="line">for page in range(1,max_page+1):</span><br><span class="line">    #获取网页源代码</span><br><span class="line">    print(&#39;crawling the page is &#123;&#125;&#39;.format(page))  </span><br><span class="line">    url&#x3D; f&#39;http:&#x2F;&#x2F;guba.eastmoney.com&#x2F;list,zssh000001,f_&#123;page&#125;.html&#39;  </span><br><span class="line">    response  &#x3D; requests.get(url, headers&#x3D;headers) </span><br><span class="line">    #解析网页源代码</span><br><span class="line">    root &#x3D; etree.HTML(response.text)  </span><br><span class="line">    title &#x3D; root.xpath(&quot;&#x2F;&#x2F;div[contains(@class,&#39;articleh normal_post&#39;)]&#x2F;&#x2F;span[@class&#x3D;&#39;l3 a3&#39;]&#x2F;&#x2F;a&#x2F;&#x2F;text()&quot;)  </span><br><span class="line">    time &#x3D; root.xpath(&quot;&#x2F;&#x2F;div[contains(@class,&#39;articleh normal_post&#39;)]&#x2F;&#x2F;span[@class&#x3D;&#39;l5 a5&#39;]&#x2F;&#x2F;text()&quot;)  </span><br><span class="line">    all_title +&#x3D; title  #保存到总数组上</span><br><span class="line">    all_time  +&#x3D; time </span><br></pre></td></tr></table></figure><h3 id="3-4-保存结果"><a href="#3-4-保存结果" class="headerlink" title="3.4 保存结果"></a>3.4 保存结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_raw &#x3D; pd.DataFrame()  </span><br><span class="line">data_raw[&#39;title&#39;] &#x3D; all_title  </span><br><span class="line">data_raw[&#39;time&#39;] &#x3D; all_time  </span><br><span class="line">data_raw.to_excel(&#39;.&#x2F;&#x2F;data_raw.xlsx&#39;, index&#x3D;False)  </span><br></pre></td></tr></table></figure><p>输出结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/huilafh.png" alt="img"></p><p> </p><h2 id="4-情绪打分"><a href="#4-情绪打分" class="headerlink" title="4. 情绪打分"></a>4. 情绪打分</h2><p>不久之前，百度正式发布情感预训练模型 SKEP (Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis)。通过利用情感知识增强预训练模型，SKEP 在 14 项中英情感分析典型任务上全面超越 SOTA。</p><p>具体实现原理，详见「SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis」。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!pip install paddlehub</span><br><span class="line"></span><br><span class="line">import paddlehub as hub</span><br><span class="line">data_raw &#x3D; pd.read_excel(&quot;.\\data_raw.xlsx&quot;)</span><br><span class="line">data_raw[&#39;time&#39;] &#x3D; pd.to_datetime(&#39;2020 &#39;+data_raw[&#39;time&#39;])</span><br><span class="line">##这里使用了百度开源的成熟NLP模型来预测情感倾向</span><br><span class="line">senta &#x3D; hub.Module(name&#x3D;&quot;senta_bilstm&quot;)</span><br><span class="line">texts &#x3D; data_raw[&#39;title&#39;].tolist()</span><br><span class="line">input_data &#x3D; &#123;&#39;text&#39;:texts&#125;</span><br><span class="line">res &#x3D; senta.sentiment_classify(data&#x3D;input_data)</span><br><span class="line">data_raw[&#39;pos_p&#39;] &#x3D; [x[&#39;positive_probs&#39;] for x in res]</span><br><span class="line">##重采样至五分钟</span><br><span class="line">data_raw.index &#x3D; data_raw[&#39;time&#39;]</span><br><span class="line">data &#x3D; data_raw.resample(&#39;15min&#39;).mean().reset_index()</span><br></pre></td></tr></table></figure><p>部分股本评论的情感评分如下：</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/kiohfl.png" alt="img"></p><p>可以看出，上述情感评分具有一定借鉴意义。</p><p> </p><h2 id="5-获取上证指数分时数据"><a href="#5-获取上证指数分时数据" class="headerlink" title="5. 获取上证指数分时数据"></a>5. 获取上证指数分时数据</h2><p><code>AkShare</code> 是基于 Python 的财经数据接口库，可以实现对股票、期货、期权、基金、外汇、债券、指数、数字货币等金融产品的基本面数据、历史行情数据、以及衍生数据的快速采集和清洗。接下来，我们将使用 <code>AKShare</code> 库获取上证指数分时数据，具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#pip instasll akshare --usre</span><br><span class="line">import akshare as ak</span><br><span class="line">sz_index &#x3D; ak.stock_zh_a_minute(symbol&#x3D;&#39;sh000001&#39;, period&#x3D;&#39;15&#39;, adjust&#x3D;&quot;qfq&quot;)</span><br><span class="line">sz_index[&#39;day&#39;] &#x3D; pd.to_datetime(sz_index[&#39;day&#39;])</span><br><span class="line">sz_index[&#39;close&#39;] &#x3D; sz_index[&#39;close&#39;].astype(&#39;float&#39;)</span><br><span class="line">data &#x3D; data.merge(sz_index,left_on&#x3D;&#39;time&#39;,right_on&#x3D;&#39;day&#39;,how&#x3D;&#39;inner&#39;)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">matplotlib.use(&#39;Qt5Agg&#39;)</span><br><span class="line">data.index &#x3D; data[&#39;time&#39;]</span><br><span class="line">data[[&#39;pos_p&#39;,&#39;close&#39;]].plot(secondary_y&#x3D;[&#39;close&#39;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/%E5%93%88%E9%A3%9E%E8%B7%AF%E5%AE%9D%EF%BC%8Csjbgb.png" alt="img"></p><p>可以看出，情绪相对于上证指数存在一个滞后效应。在初始的大幅上涨中，情绪没有立刻上涨，而是在第二次小幅上涨后才出现大幅度的上升。</p><p> </p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>总的来说不难，但步骤很丰富，在完善完善就是一个中等项目了哈哈哈哈哈</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 情感分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python爬虫入门首选，Requests+正则/Xpath</title>
      <link href="2021/01/10/Python%E5%85%A5%E9%97%A8%E9%A6%96%E9%80%89%EF%BC%8CRequests%20%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>2021/01/10/Python%E5%85%A5%E9%97%A8%E9%A6%96%E9%80%89%EF%BC%8CRequests%20%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Python爬虫入门首选，Requests-正则-Xpath"><a href="#Python爬虫入门首选，Requests-正则-Xpath" class="headerlink" title="Python爬虫入门首选，Requests+正则/Xpath"></a>Python爬虫入门首选，Requests+正则/Xpath</h1><iframe id="pqvE7xEK-1596373719908" src="https://player.bilibili.com/player.html?aid=756043858" allowfullscreen="true" data-mediaembed="bilibili" __idm_id__="291592193" style="box-sizing: border-box; outline: 0px; margin: 0px; padding: 0px; font-weight: normal; overflow-wrap: break-word; display: block; width: 660px; height: 330px;"></iframe><p>学习完Python基本知识，我们就可以正式步入Python 爬虫的大门。</p><p>学习爬虫，最基础的便是模拟浏览器向服务器发出请求，那么我们需要从什么地方做起呢？请求需要我们自己来构造吗？需要关心请求这个数据结构的实现吗？需要了解 HTTP、TCP、IP 层的网络传输通信吗？需要知道服务器的响应和应答原理吗？</p><p>可能你无从下手，不过不用担心，Python 的强大之处就是提供了功能齐全的类库来帮助我们完成这些请求。利用 Python 现有的库我们可以非常方便地实现网络请求的模拟，常见的库有 urllib、requests 等。</p><p>拿 requests 这个库来说，有了它，我们只需要关心请求的链接是什么，需要传的参数是什么，以及如何设置可选的参数就好了，不用深入到底层去了解它到底是怎样传输和通信的。有了它，两行代码就可以完成一个请求和响应的处理过程，非常方便地得到网页内容。</p><p>接下来，就让我们用 Python 的 requests 库开始我们的爬虫之旅吧。</p><p><a href="https://requests.readthedocs.io/en/master/">Requests官方文档</a>   <a href="https://requests.readthedocs.io/zh_CN/latest/">中文文档</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>首先，requests 库是 Python 的一个第三方库，不是自带的。所以我们需要额外安装（<strong>Anaconda自带丰富库，可跳过此步</strong>）。</p><p>在这之前需要你先安装好 Python3 环境，如 Python 3.8 版本。</p><p>安装好 Python3 之后，我们使用 pip3 即可轻松地安装好 requests 库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install requests</span><br></pre></td></tr></table></figure><p>由于科学上网的原因，国外的第三方库官方下载龟速，请pip换源建议清华镜像。</p><p>安装完成之后，我们就可以开始我们的网络爬虫之旅了。</p><h3 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h3><p>用 Python 写爬虫的第一步就是模拟发起一个请求，把网页的源代码获取下来。</p><p>当我们在浏览器中输入一个 URL 并回车，实际上就是让浏览器帮我们发起一个 GET 类型的 HTTP 请求，浏览器得到源代码后，把它渲染出来就可以看到网页内容了。</p><p>那如果我们想用 requests 来获取源代码，应该怎么办呢？很简单，requests 这个库提供了一个 get 方法，我们调用这个方法，并传入对应的 URL 就能得到网页的源代码。</p><p>比如这里有一个示例网站：<a href="https://zhangkaiheng.gitee.io/%EF%BC%8C%E5%85%B6%E5%86%85%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A">https://zhangkaiheng.gitee.io/，其内容如下：</a></p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102221113.png"></p><p>哈哈哈哈哈哈！竟然到了爬自己博客的地步！！！</p><p>第一步当然就是获取它的网页源代码了。</p><p>我们可以用 requests 这个库轻松地完成这个过程，代码的写法是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang&#x3D;&quot;zh-CN&quot; data-theme&#x3D;&quot;light&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset&#x3D;&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width,initial-scale&#x3D;1&quot;&gt;</span><br><span class="line">    &lt;title&gt;爱爬虫与大数据&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;keywords&quot; content&#x3D;&quot;爱爬虫与大数据&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;author&quot; content&#x3D;&quot;Kit&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;copyright&quot; content&#x3D;&quot;Kit&quot;&gt;</span><br><span class="line">    ...</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;div id&#x3D;&quot;sidebar&quot;&gt;</span><br><span class="line">        &lt;div id&#x3D;&quot;menu-mask&quot;&gt;&lt;&#x2F;div&gt;</span><br><span class="line">        &lt;div id&#x3D;&quot;sidebar-menus&quot;&gt;</span><br><span class="line">...  </span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><p>由于网页内容比较多，这里省略了大部分内容。</p><p>不过看运行结果，我们已经成功获取网页的 HTML 源代码，里面包含了电影的标题、类型、上映时间，等等。把网页源代码获取下来之后，下一步我们把想要的数据提取出来，数据的爬取就完成了。</p><p>这个实例的目的是让你体会一下 requests 这个库能帮我们实现什么功能。我们仅仅用 requests 的 get 方法就成功发起了一个 GET 请求，把网页源代码获取下来了，是不是很方便呢？</p><h3 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h3><p>HTTP 中最常见的请求之一就是 GET 请求，下面我们来详细了解利用 requests 库构建 GET 请求的方法。</p><h4 id="GET-请求"><a href="#GET-请求" class="headerlink" title="GET 请求"></a>GET 请求</h4><p>我们换一个示例网站，其 URL 为 <a href="http://httpbin.org/get%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E8%B5%B7%E7%9A%84%E6%98%AF">http://httpbin.org/get，如果客户端发起的是</a> GET 请求的话，该网站会判断并返回相应的请求信息，包括 Headers、IP 等。</p><p>我们还是用相同的方法来发起一个 GET 请求，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;,</span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,</span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;,</span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff98684-119fbcba4197a62114bac501&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;,</span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;get&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，我们成功发起了 GET 请求，也通过这个网站的返回结果得到了请求所携带的信息，包括 Headers、URL、IP，等等。</p><p>对于 GET 请求，我们知道 URL 后面是可以跟上一些参数的，如果我们现在想添加两个参数，其中 name 是 kit，age 是 25，URL 就可以写成如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19</span><br></pre></td></tr></table></figure><p>要构造这个请求链接，是不是要直接写成这样呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19&#39;)</span><br></pre></td></tr></table></figure><p>这样也可以，但如果这些参数还需要我们手动拼接，未免有点不人性化。</p><p>一般情况下，这种信息我们利用 params 这个参数就可以直接传递了，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">data &#x3D; &#123;  </span><br><span class="line">    &#39;name&#39;: &#39;kit&#39;,  </span><br><span class="line">    &#39;age&#39;: 19</span><br><span class="line">&#125; </span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;, params&#x3D;data)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;</span><br><span class="line">    &quot;age&quot;: &quot;19&quot;, </span><br><span class="line">    &quot;name&quot;: &quot;kit&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;, </span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, </span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;, </span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff99fab-4dc3d0207d4376fd6923f0c4&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;, </span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这里我们把 URL 参数通过字典的形式传给 get 方法的 params 参数，通过返回信息我们可以判断，请求的链接自动被构造成了：<a href="http://httpbin.org/get?name=kit&amp;age=19%EF%BC%8C%E8%BF%99%E6%A0%B7%E6%88%91%E4%BB%AC%E5%B0%B1%E4%B8%8D%E7%94%A8%E5%86%8D%E5%8E%BB%E8%87%AA%E5%B7%B1%E6%9E%84%E9%80%A0">http://httpbin.org/get?name=kit&amp;age=19，这样我们就不用再去自己构造</a> URL 了，非常方便。</p><p>另外，网页的返回类型实际上是 str 类型，但是它很特殊，是 JSON 格式的。所以，如果想直接解析返回结果，得到一个 JSON 格式的数据的话，可以直接调用 json 方法。</p><p>示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;)  </span><br><span class="line">print(type(r.text))  </span><br><span class="line">print(r.json())  </span><br><span class="line">print(type(r.json()))</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#39;str&#39;&gt;</span><br><span class="line">&#123;&#39;args&#39;: &#123;&#125;, &#39;headers&#39;: &#123;&#39;Accept&#39;: &#39;*&#x2F;*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests&#x2F;2.24.0&#39;, &#39;X-Amzn-Trace-Id&#39;: </span><br><span class="line">&#39;Root&#x3D;1-5ff987e4-1248c4cd04158eed34ca44c5&#39;&#125;, &#39;origin&#39;: &#39;112.32.241.87&#39;, &#39;url&#39;: &#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;&#125;</span><br><span class="line">&lt;class &#39;dict&#39;&gt;</span><br></pre></td></tr></table></figure><p>可以发现，调用 json 方法，就可以将返回结果是 JSON 格式的字符串转化为字典。</p><p>但需要注意的是，如果返回结果不是 JSON 格式，便会出现解析错误，抛出 json.decoder.JSONDecodeError 异常。</p><h4 id="解析网页"><a href="#解析网页" class="headerlink" title="解析网页"></a>解析网页</h4><p>上面的请求链接返回的是 JSON 形式的字符串，那么如果请求普通的网页，则肯定能获得相应的内容了。下面以本课时最初的实例页面为例，我们再加上一点提取信息的逻辑，将代码完善成如下的样子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;)</span><br><span class="line">pattern &#x3D; re.compile(&#39;&lt;p class&#x3D;&quot;name&quot;&gt;&lt;a href&#x3D;&quot;&#x2F;films&#x2F;.*?&gt;(.*?)&lt;&#x2F;a&gt;&#39;, re.S)</span><br><span class="line">titles &#x3D; re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br></pre></td></tr></table></figure><p>在这个例子中我们用到了最基础的正则表达式来匹配出所有的标题。关于正则表达式的相关内容，我们会在下一课时详细介绍，这里作为实例来配合讲解。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#39;我不是药神&#39;, &#39;肖申克的救赎&#39;, &#39;绿皮书&#39;, &#39;海上钢琴师&#39;, &#39;哪吒之魔童降世&#39;, &#39;小偷家族&#39;, &#39;霸王别姬&#39;, &#39;美丽人生&#39;, &#39;盗梦空间&#39;, &#39;这个杀手不太冷&#39;]</span><br></pre></td></tr></table></figure><p>我们发现，这里成功提取出了所有的电影标题。一个最基本的抓取和提取流程就完成了。</p><h4 id="添加-headers"><a href="#添加-headers" class="headerlink" title="添加 headers"></a>添加 headers</h4><p>我们知道，在发起一个 HTTP 请求的时候，会有一个请求头 Request Headers，那么这个怎么来设置呢？</p><p>很简单，我们使用 headers 参数就可以完成了。</p><p>在刚才的实例中，实际上我们是没有设置 Request Headers 信息的，如果不设置，某些网站会发现这不是一个正常的浏览器发起的请求，网站可能会返回异常的结果，导致网页抓取失败。</p><p>要添加 Headers 信息，比如我们这里想添加一个 User-Agent 字段，我们可以这么来写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;, headers&#x3D;headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>当然，我们可以在 headers 这个参数中任意添加其他的字段信息。</p><h4 id="POST-请求"><a href="#POST-请求" class="headerlink" title="POST 请求"></a>POST 请求</h4><p>前面我们了解了最基本的 GET 请求，另外一种比较常见的请求方式是 POST。使用 requests 实现 POST 请求同样非常简单，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">data &#x3D; &#123;&#39;name&#39;: &#39;kit&#39;, &#39;age&#39;: &#39;20&#39;&#125;</span><br><span class="line">r &#x3D; requests.post(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;, data&#x3D;data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>这里还是请求 <a href="http://httpbin.org/post%EF%BC%8C%E8%AF%A5%E7%BD%91%E7%AB%99%E5%8F%AF%E4%BB%A5%E5%88%A4%E6%96%AD%E5%A6%82%E6%9E%9C%E8%AF%B7%E6%B1%82%E6%98%AF">http://httpbin.org/post，该网站可以判断如果请求是</a> POST 方式，就把相关请求信息返回。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;, </span><br><span class="line">  &quot;data&quot;: &quot;&quot;, </span><br><span class="line">  &quot;files&quot;: &#123;&#125;, </span><br><span class="line">  &quot;form&quot;: &#123;</span><br><span class="line">    &quot;age&quot;: &quot;20&quot;, </span><br><span class="line">    &quot;name&quot;: &quot;kit&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;, </span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, </span><br><span class="line">    &quot;Content-Length&quot;: &quot;15&quot;, </span><br><span class="line">    &quot;Content-Type&quot;: &quot;application&#x2F;x-www-form-urlencoded&quot;,         </span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;, </span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff99ef7-1d4426a80c49df9d31ff3250&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;json&quot;: null, </span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;, </span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，我们成功获得了返回结果，其中 form 部分就是提交的数据，这就证明 POST 请求成功发送了。</p><h3 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h3><p>发送请求后，得到的自然就是响应，即 Response。</p><p>在上面的实例中，我们使用 text 和 content 获取了响应的内容。此外，还有很多属性和方法可以用来获取其他信息，比如状态码、响应头、Cookies 等。示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)</span><br><span class="line">print(type(r.status_code), r.status_code)</span><br><span class="line">print(type(r.headers), r.headers)</span><br><span class="line">print(type(r.cookies), r.cookies)</span><br><span class="line">print(type(r.url), r.url)</span><br><span class="line">print(type(r.history), r.history)</span><br></pre></td></tr></table></figure><p>这里分别打印输出 status_code 属性得到状态码，输出 headers 属性得到响应头，输出 cookies 属性得到 Cookies，输出 url 属性得到 URL，输出 history 属性得到请求历史。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#39;int&#39;&gt; 200</span><br><span class="line">&lt;class &#39;requests.structures.CaseInsensitiveDict&#39;&gt; &#123;&#39;Date&#39;: &#39;Sat, 09 Jan 2021 12:54:40 GMT&#39;, &#39;Content-Type&#39;: &#39;text&#x2F;html&#39;, &#39;Transfer-Encoding&#39;: &#39;chunked&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Server&#39;: &#39;openresty&#x2F;1.13.6.2&#39;, &#39;Last-Modified&#39;: &#39;Mon, 04 Jan 2021 07:53:48 GMT&#39;, &#39;ETag&#39;: &#39;W&#x2F;&quot;5ff2c98c-9df5&quot;&#39;, &#39;Expires&#39;: &#39;Sun, 10 Jan 2021 12:54:40 GMT&#39;, &#39;Cache-Control&#39;: &#39;max-age&#x3D;86400&#39;, &#39;Content-Encoding&#39;: &#39;gzip&#39;&#125;</span><br><span class="line">&lt;class &#39;requests.cookies.RequestsCookieJar&#39;&gt; &lt;RequestsCookieJar[]&gt;</span><br><span class="line">&lt;class &#39;str&#39;&gt; https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;</span><br><span class="line">&lt;class &#39;list&#39;&gt; []</span><br></pre></td></tr></table></figure><p>可以看到，headers 和 cookies 这两个属性得到的结果分别是 CaseInsensitiveDict 和 RequestsCookieJar 类型。</p><p>我们知道，<a href="https://baike.baidu.com/item/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/5053660?fr=aladdin">状态码</a>是用来表示响应状态的，比如返回 200 代表我们得到的响应是没问题的，上面的例子正好输出的结果也是 200，所以我们可以通过判断 Response 的状态码来确认是否爬取成功。</p><p>requests 还提供了一个内置的状态码查询对象 requests.codes，用法示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)</span><br><span class="line">exit() if not r.status_code &#x3D;&#x3D; requests.codes.ok else print(&#39;Request Successfully&#39;)</span><br></pre></td></tr></table></figure><p>这里通过比较返回码和内置的成功的返回码，来保证请求得到了正常响应，输出成功请求的消息，否则程序终止，这里我们用 requests.codes.ok 得到的是成功的状态码 200。</p><p>这样的话，我们就不用再在程序里面写状态码对应的数字了，用字符串表示状态码会显得更加直观。</p><h1 id="爬虫入门首选开刀网站——猫眼电影"><a href="#爬虫入门首选开刀网站——猫眼电影" class="headerlink" title="爬虫入门首选开刀网站——猫眼电影"></a>爬虫入门首选开刀网站——猫眼电影</h1><h2 id="爬虫准备"><a href="#爬虫准备" class="headerlink" title="爬虫准备"></a>爬虫准备</h2><p>猫眼电影是美团旗下的一家集媒体内容、在线购票、用户互动社交、电影衍生品销售等服务的一站式电影互联网平台。2015年6月，猫眼电影覆盖影院超过4000家，这些影院的票房贡献占比超过90%。目前，猫眼占网络购票70%的市场份额，每三张电影票就有一张出自猫眼电影，是影迷下载量较多、使用率较高的电影应用软件。同时，猫眼电影为合作影院和电影制片发行方提供覆盖海量电影消费者的精准营销方案，助力影片票房。</p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109211910.png"></p><p>运行平台：win10</p><p>Python版本：3.8</p><p>IDE：Pycharm</p><p>浏览器：Chrome</p><p>目标：获取猫眼Top100电影名称、主演、上映时间、评分、封面图片</p><p>如此网站数据看上去都心动，不过猫眼电影也是有反爬机制的，只不过今天我们的入门小打小闹触及不深。</p><h2 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h2><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png"></p><p>通过F12或者右键选择检查我们发现两个规律：</p><ol><li>要获取的数据有规律的存在网页代码中：如标题在class属性为name的p标签里、主演在class属性为star的p标签里······</li><li>第一页链接offset=0而第二页链接offset=10推测第三页offset=20</li></ol><h2 id="请求网页"><a href="#请求网页" class="headerlink" title="请求网页"></a>请求网页</h2><p>分析完网页我们可以试着模拟浏览器请求网页</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>为了保证爬虫正常，添加请求头</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">  &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;, headers&#x3D;headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>试着利用最简单的正则获取第一页的标题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">  &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;, headers&#x3D;headers)</span><br><span class="line">pattern &#x3D; re.compile(&#39;&lt;p class&#x3D;&quot;name&quot;&gt;&lt;a href&#x3D;&quot;&#x2F;films&#x2F;.*?&gt;(.*?)&lt;&#x2F;a&gt;&#39;, re.S)</span><br><span class="line">titles &#x3D; re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br><span class="line"># 运行结果</span><br><span class="line"># [&#39;我不是药神&#39;, &#39;肖申克的救赎&#39;, &#39;绿皮书&#39;, &#39;海上钢琴师&#39;, &#39;哪吒之魔童降世&#39;, &#39;小偷家族&#39;, &#39;霸王别姬&#39;, &#39;美丽人生&#39;, &#39;盗梦空间&#39;, &#39;这个杀手不太冷&#39;]</span><br></pre></td></tr></table></figure><p>针对规律一我们很容易利用正则解析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 主演</span><br><span class="line">star &#x3D; re.findall(re.compile(&#39;&lt;p class&#x3D;&quot;star&quot;&gt;(.*?)&lt;&#x2F;p&gt;&#39;, re.S), r.text)</span><br><span class="line"># 发表时间</span><br><span class="line">releasetime &#x3D; re.findall(re.compile(&#39;&lt;p class&#x3D;&quot;releasetime&quot;&gt;(.*?)&lt;&#x2F;p&gt;&#39;, re.S), r.text)</span><br><span class="line"># 封面链接</span><br><span class="line">img_urls &#x3D; re.findall(re.compile(&#39;&lt;img data-src&#x3D;&quot;(.*?)&quot; alt&#x3D;&quot;.*?&quot; class&#x3D;&quot;board-img&quot; &#x2F;&gt;&#39;, re.S), r.text)</span><br><span class="line"># 排名</span><br><span class="line">top &#x3D; re.findall(re.compile(&#39;&lt;i class&#x3D;&quot;board-index board-index-.*?&quot;&gt;(.*?)&lt;&#x2F;i&gt;&#39;, re.S), r.text)</span><br></pre></td></tr></table></figure><p>不写了。。。看<a href="https://www.bilibili.com/video/BV1Kr4y1T7z8/">视频</a>听口述吧代码自己敲别<a href="https://github.com/Kit139/maoyan_movies">copyme</a></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CIT </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量</title>
      <link href="2021/01/02/20210102%E5%AF%92%E5%81%87%E7%AC%AC%E4%B8%80%E4%BA%A4%E6%B5%81%E4%BC%9A%E2%80%94%E2%80%94%E9%BB%91%E5%B1%8F%E8%A7%81%E7%BF%BB%E8%BD%A6%EF%BC%9F%E4%B8%8D%EF%BC%81%E6%88%91%E5%9C%A8%E6%A3%80%E6%B5%8B%E8%AE%A4%E7%9C%9F%E8%B4%A8%E9%87%8F/"/>
      <url>2021/01/02/20210102%E5%AF%92%E5%81%87%E7%AC%AC%E4%B8%80%E4%BA%A4%E6%B5%81%E4%BC%9A%E2%80%94%E2%80%94%E9%BB%91%E5%B1%8F%E8%A7%81%E7%BF%BB%E8%BD%A6%EF%BC%9F%E4%B8%8D%EF%BC%81%E6%88%91%E5%9C%A8%E6%A3%80%E6%B5%8B%E8%AE%A4%E7%9C%9F%E8%B4%A8%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量"><a href="#20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量" class="headerlink" title="20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量"></a>20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量</h1><iframe id="pqvE7xEK-1596373719908" src="https://player.bilibili.com/player.html?aid=330946159" allowfullscreen="true" data-mediaembed="bilibili" __idm_id__="291592193" style="box-sizing: border-box; outline: 0px; margin: 0px; padding: 0px; font-weight: normal; overflow-wrap: break-word; display: block; width: 660px; height: 330px;"></iframe><h2 id="明晰定位，确立方向"><a href="#明晰定位，确立方向" class="headerlink" title="明晰定位，确立方向"></a>明晰定位，确立方向</h2><ul><li>Python——除了生孩子不可以其他啥都行不假但不适合任何人</li><li>编程——工管人、经济人躲不掉</li><li>编程触类旁通——学Python培养编程思维利VB</li></ul><h2 id="选课推荐"><a href="#选课推荐" class="headerlink" title="选课推荐"></a>选课推荐</h2><ul><li>数学建模</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102220412.png"></p><ul><li><p>Python程序设计</p></li><li><p>MS高级应用</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102220812.png"></p><h2 id="互动环节"><a href="#互动环节" class="headerlink" title="互动环节"></a>互动环节</h2><p>主修与辅修</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>利用好github、gitee</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102221419.png"></p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102221202.png"></p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102220935.png"></p><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102221113.png"></p><ul><li><p>作业任务</p><p>一星期过一遍Python<a href="https://www.w3school.com.cn/python/index.asp">基础知识</a>和<a href="https://www.bilibili.com/video/BV1ta411w7D3">回放</a>等</p><p>查找资料预习爬虫(可以看看<a href="https://www.bilibili.com/video/BV1NE411Q7i2">解师哥的视频</a>注意有P2) </p><p>下周六个人学习总结分享 </p><p>B站、知乎、微信公众号等开源资源要利用好</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> CIT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CIT </tag>
            
            <tag> Python </tag>
            
            <tag> 选课 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>给hexo Butterfly扩展图标</title>
      <link href="2020/12/28/%E7%BB%99hexo%20Butterfly%E6%89%A9%E5%B1%95%E5%9B%BE%E6%A0%87/"/>
      <url>2020/12/28/%E7%BB%99hexo%20Butterfly%E6%89%A9%E5%B1%95%E5%9B%BE%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1 id="给hexo-Butterfly扩展图标"><a href="#给hexo-Butterfly扩展图标" class="headerlink" title="给hexo Butterfly扩展图标"></a>给hexo Butterfly扩展图标</h1><p>由于hexo butterfly主题采用了Font Awesome图标（不包含如B站，知乎这类中国大陆网站的图标）所以如果需要使用的话需要额外自行添加</p><h2 id="Font-Awesome相关知识"><a href="#Font-Awesome相关知识" class="headerlink" title="Font Awesome相关知识"></a><a href="http://www.fontawesome.com.cn/">Font Awesome</a>相关知识</h2><p>引用<a href="https://zh.wikipedia.org/wiki/Font_Awesome">维基百科</a>中的介绍</p><blockquote><p>Font Awesome 是一个基于CSS和LESS的字体和图标工具套件。它由Dave Gandy制作，用于Twitter Bootstrap，后来被整合到BootstrapCDN 中。Font Awesome在使用第三方Font Scripts的网站中占有20％的市场份额，排在Google字型之后的第二位。</p></blockquote><p>简单的说，Font Awesome是一个图标库，当你的博客需要使用一个图标时（比如）</p><p>由于next已经使用了Font Awesome，所以只需要插入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;i class&#x3D;&quot;fab fa-github&quot;&gt;&lt;&#x2F;i&gt;</span><br></pre></td></tr></table></figure><p>即可。具体的Font Awesome使用方法可以看<a href="https://www.runoob.com/font-awesome/fontawesome-tutorial.html">菜鸟教程</a></p><h2 id="第三方图标库的使用"><a href="#第三方图标库的使用" class="headerlink" title="第三方图标库的使用"></a>第三方图标库的使用</h2><p>由于Font Awesome图标不包含如B站，知乎这类中国大陆网站的图标，所以如果需要使用的话需要额外自行添加第三方的图标库，在这里，我们使用使用<a href="https://www.iconfont.cn/">阿里巴巴矢量库</a></p><h3 id="下载图标"><a href="#下载图标" class="headerlink" title="下载图标"></a>下载图标</h3><p>首先，我们在阿里巴巴图标库挑选需要的图标，具体可以使用搜索功能进行搜索，在图标上点击添加入库将其加入库中，之后点击右上方购物车图标，点击下载代码获得一个压缩文件</p><h3 id="使用下载的图标"><a href="#使用下载的图标" class="headerlink" title="使用下载的图标"></a>使用下载的图标</h3><p>打开文件中的<code>iconfont.css</code>，将其中的内容（比如这样）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">@font-face &#123;font-family: &quot;iconfont&quot;;</span><br><span class="line">    src: url(&#39;iconfont.eot?t&#x3D;1589906807175&#39;); &#x2F;* IE9 *&#x2F;</span><br><span class="line">    src: url(&#39;iconfont.eot?t&#x3D;1589906807175#iefix&#39;) format(&#39;embedded-opentype&#39;), &#x2F;* IE6-IE8 *&#x2F;</span><br><span class="line">    url(&#39;data:application&#x2F;x-font-woff2;charset&#x3D;utf-8;base64,d09GMgABAAAAAAiAAAsAAAAAD0AAAAgzAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHEIGVgCDNgqRPI4HATYCJAMYCw4ABCAFhG0HXxuyDCMR9oOSQpP9RYJ5yE75AyR1CmZsFOu9SJ3BIn3W9BPb&#x2F;Ad3h9hYq2CuK9yPrpD4rxP35f5dCEIazng0oUypUg1gxStcoQJ2sK5Mrk5aBxUGhfHrIJXedPa780X2JD+rwebUuibgQmWZsHTyyT3kZCsny23&#x2F;A+BgzdWJJ+8bcJj28nLIzRxTTeQlQiYkEW&#x2F;&#x2F;JGskqBAKIUYqObPoZoWJJy1mwQMT&#x2F;bqbAQVAxIILao1LyQEWBnZKDng01lcCWwjALQYK62aIEwuoNxDsNIo+CwATou+n&#x2F;uAVFoBGGsCBGXWxNRDxXKTXI6mXSgIJIF8xAKxPA0AAXABgQF1kaQ2ghFwih4jqjgUAYHEzGjwXP5&#x2F;9olSv1ypR&#x2F;qMUs0TqHx4ADUMIoAaAQ6KUKW0EPBdZfJEofYBPztkyHSDwojQNEPKcLPhoHoax2hcgWYaeAB4X&#x2F;qE8RAAXZ44yVIjdDS0kao0NQxQsVsVKoqptNiISVtb8uVguQCAwl0hEQmNDB04q7SKhpMVjzgG+L4pkoy9TpJqZ39hZBpc6ecvm3EXCXe3nSF0bQXsLdoZsr+0gsOxTD6rxV0d2N&#x2F;Z6zcbWiga7qssQ1XpQX5xzc6t7jtZoPiE0oDcqYtVpXdmjYQgV7z7icaUyITtaY9SU7FK9Zu3007LNqHJbYYMx2RvaKBVK8dpZPX5Zra&#x2F;vOVxVtzrXrFebWHEqfaPraM1IReuuwdQmASUh8zVWy&#x2F;djiKC1AARiCY&#x2F;XJHCgmUqHgS+gfDjFlkAixLAHIVnLS75d3A+f8bSUVyOobdMEE6IUAUs0pHOaDm&#x2F;ad0AM&#x2F;NupIkxx7cNo8sojtetmG5evk5q1OU3kORbOEpfdMQL4FGYLdsMA5UjQC++rNGSIwyGO+CgOZ1ApxEfmYzP+yA2kNXY1wPfHSpeI&#x2F;Jv4vWp8glc3&#x2F;J2qMGouX4ZYvZvFIoy2N0VEersaO6Fw0IxWFQEcRHYUkSC+9TvljkrXNly8fVrcf4Adgec9QLaL5uF3NYWqc+9IRLoK1pX+68qYQ2gcO3Eq0uRFlLhpzOSLo+gepfeLdzzBucnErmrINJq19bJO+GGoVBD4zxUshEniZutk&#x2F;diXkauhX19dy5GrYEVyNVtXj7v&#x2F;bpAEE1nv1XL4zcFCefWS2NhzxFP7NgF9b9x78rcV8vT+zRQatOXAGbE4b&#x2F;qgNWMqZUt3GtED19m2rthjigbtr1i2CmDgytGrKaplWXXuefb2HHBgwEaKt9TeseH4ezzY&#x2F;LRy3nHAqIhRUQPDIXz&#x2F;vzG0LdZ3RNLKIumJ+AWqN9KmFLfdXyC0bWPUZlggPOl26a2ZIIFJveRidCc8Uzrsg31Ps+Gd4i4Lqx5l6Mat7M5bR3tY2XpoC+p4z0tfJwvyDdJSC7lYWu56ZLPseGQB2z1ydmxQiYHHmyB+8Jfbmb65gVGZ9vYDD90xE7f5C&#x2F;LYXDrX6tiSK7Gik3KK97+km&#x2F;QzusBqKG9l35GhtDh38eHtadyI0g4mQZL0AeZ+1&#x2F;6YO8ZYazR3srFYhVVCBbEnCqEaq8XG2L+QxR5KARbIWKzBrCwRQFmBvfy7DlNymBNjsQIrGLUqxpufldDVe3ipWiBgMIqKJLeE1j6+Xn5+ym48vwfRhgwOxpbqDMywWJBV46jGtDWNTaREKrU5z2Ap42yNrRlxNcgI2cdE62x0MTFVNlXRMYacROPjs3e0xoSYcIQzJab+PWLssyOTil0NxwlkZEqQyoAYKBGJV8qVTiq5app5fGS8pxkRe8zqhn1It24aG&#x2F;&#x2F;Ra9zETiaus2ZGq4iWEDnBWszII4nUkXGUMdamuO6RvpbYxNsLjyjq5xkfqeXrvaQKcxmRKYlSTuTmz+RXTfHxJm5O7thnBv8vL98rv+6&#x2F;9&#x2F;uRw7yn9QSrDW0Y&#x2F;slj4Z1FeEMO49zVI4JLLU44Gkxpv76aRacguB&#x2F;3cKOvJgKfwZYjbeNdYuqKPFTZkqbEqDXCxaexoGSV0xHjKWY973SlpkYZZnZmLpmWkJxakaRJUlM34WHXbl5R5ps29uVzjI36aNOLTSschk108E2RVVmr+12qbCfdBJ+KvStsKwryS0J0aEYplYwfZkatjulAMzLpJDplum6CQaPackA+te5ylHUPsxAb&#x2F;5FTTkZu0c6L1G3T7o6Mr3nY1&#x2F;3Po77pP54gwqtp3bRpOloeYxnzMJNqaaEyFdYg68fa0qhOnggssrIfKmRSRQTgTig63shIZgqgWkSjRo00P3qWn8WfTU0ttKibVWuRZ1E7q87C6VJSmJrauuWHN04T3R1KjD9Pdge9qan3nf7cCGWucqS2Z9Dcox64V1TcUztS1oyAvgCH6He0wygYAAB9afNi8zG0G&#x2F;nq1t9oH62nyj&#x2F;I0FHaCQyP7Ffl8pBvrPh&#x2F;as3t1249dK1+RwEP77Jgb3SCsOcSfCqAIFOHmS3fK57JIeDLaeDmhPUAlUr3ucIavO0UliYDmoA5ICytFCtdgBDzAQYrHEScxZ8uptIJCFVCAHAyTACFswFoMgcA4ZyTYuU9IAy8AwYXBCJ5lOqCYgsc0rg5MSpBC&#x2F;oPKkO9M2HZxAPvWIRWcb4gsr6RfdUAWZyWO27YI3Mc4j9FLuLAMXVwFbfDtiUYmGo0EpciwzFJHHVobKgbbZwYlQQpLdB&#x2F;eStDvYstm8rX37EIreKWGY9538i+Wj&#x2F;IxNIe0puj7zXjrQz3nyInqtiBbWbqEtdVF2OLrQQGersajcTKEc3DUaJWcn0d8fKu7lt2+PpmBbFGprRUekZmi5OCVv3MeNvP&#x2F;8uqDHsJulKUWf8DRXt&#x2F;W9miyNT0OBoBAA&#x3D;&#x3D;&#39;) format(&#39;woff2&#39;),</span><br><span class="line">    url(&#39;iconfont.woff?t&#x3D;1589906807175&#39;) format(&#39;woff&#39;),</span><br><span class="line">    url(&#39;iconfont.ttf?t&#x3D;1589906807175&#39;) format(&#39;truetype&#39;), &#x2F;* chrome, firefox, opera, Safari, Android, iOS 4.2+ *&#x2F;</span><br><span class="line">    url(&#39;iconfont.svg?t&#x3D;1589906807175#iconfont&#39;) format(&#39;svg&#39;); &#x2F;* iOS 4.1- *&#x2F;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .iconfont &#123;</span><br><span class="line">    font-family: &quot;iconfont&quot; !important;</span><br><span class="line">    font-size: 16px;</span><br><span class="line">    font-style: normal;</span><br><span class="line">    -webkit-font-smoothing: antialiased;</span><br><span class="line">    -moz-osx-font-smoothing: grayscale;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .icon-douban:before &#123;</span><br><span class="line">    content: &quot;\f01c8&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .icon-csdn:before &#123;</span><br><span class="line">    content: &quot;\e60a&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .icon-zhihu:before &#123;</span><br><span class="line">    content: &quot;\e69a&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .icon-tubiaozhizuo-:before &#123;</span><br><span class="line">    content: &quot;\e60b&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  .icon-bilibili-line:before &#123;</span><br><span class="line">    content: &quot;\e75d&quot;;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>全部复制到<code>\blogs\themes\next\source\lib\font-awesome\css\all.min.css</code>后边。这样，就可以使用新添加的图标了</p><p>：<code>&lt;i class=&quot;iconfont icon-bilibili-line&quot;&gt;&lt;/i&gt;</code></p><h3 id="在侧栏的社交链接中加入bilibili"><a href="#在侧栏的社交链接中加入bilibili" class="headerlink" title="在侧栏的社交链接中加入bilibili"></a>在侧栏的社交链接中加入bilibili</h3><p>打开_config.butterfly.yml或者_config.yml文件，搜索找到social：增加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bilibili: https:&#x2F;&#x2F;space.bilibili.com&#x2F;B站id || iconfont icon-bilibili-line</span><br></pre></td></tr></table></figure><p>修改完如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">social:</span><br><span class="line">  #GitHub: https:&#x2F;&#x2F;github.com&#x2F;yourname || fab fa-github</span><br><span class="line">  #E-Mail: mailto:yourname@gmail.com || fa fa-envelope</span><br><span class="line">  #Weibo: https:&#x2F;&#x2F;weibo.com&#x2F;yourname || fab fa-weibo</span><br><span class="line">  #Google: https:&#x2F;&#x2F;plus.google.com&#x2F;yourname || fab fa-google</span><br><span class="line">  #Twitter: https:&#x2F;&#x2F;twitter.com&#x2F;yourname || fab fa-twitter</span><br><span class="line">  #FB Page: https:&#x2F;&#x2F;www.facebook.com&#x2F;yourname || fab fa-facebook</span><br><span class="line">  #StackOverflow: https:&#x2F;&#x2F;stackoverflow.com&#x2F;yourname || fab fa-stack-overflow</span><br><span class="line">  #YouTube: https:&#x2F;&#x2F;youtube.com&#x2F;yourname || fab fa-youtube</span><br><span class="line">  #Instagram: https:&#x2F;&#x2F;instagram.com&#x2F;yourname || fab fa-instagram</span><br><span class="line">  #Skype: skype:yourname?call|chat || fab fa-skype</span><br><span class="line">  bilibili: https:&#x2F;&#x2F;space.bilibili.com&#x2F;B站id || iconfont icon-bilibili-line</span><br></pre></td></tr></table></figure><p>把B站id换成自己的B站id即可</p><p>参考文章：<a href="https://x-zeppelin.github.io/hexo-icon/">给hexo next扩展图标</a></p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 图标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>同济校友世纪互联白票</title>
      <link href="2020/12/27/%E5%90%8C%E6%B5%8E%E6%A0%A1%E5%8F%8B%E4%B8%96%E7%BA%AA%E4%BA%92%E8%81%94%E7%99%BD%E7%A5%A8/"/>
      <url>2020/12/27/%E5%90%8C%E6%B5%8E%E6%A0%A1%E5%8F%8B%E4%B8%96%E7%BA%AA%E4%BA%92%E8%81%94%E7%99%BD%E7%A5%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="同济校友世纪互联白票"><a href="#同济校友世纪互联白票" class="headerlink" title="同济校友世纪互联白票"></a><strong>同济校友世纪互联白票</strong></h1><p>社工库免费查询：@sgk123bot  </p><p>身份户籍、手机机主、开房记录、快递地址、贷款记录、车牌车主、个人常用密码、QQ/邮箱/微博/网络账号、就职单位和银行开户等联系方式。  </p><p>【每日1次免费】 输入推广码: IVT51C7A00B 额外获得5次查询。   </p><p>学号姓名怎么获取已经知道了，tg某社工库机器人库比较全。</p><p>之所以选生僻字也是这一点，缩小范围，再根据学号可以基本确定sfz里的出生年份进一步确定姓名对应的sfz号。  <a href="https://mail-mgmt.tongji.edu.cn/regOfficialEmail/checkPhone">https://mail-mgmt.tongji.edu.cn/regOfficialEmail/checkPhone</a> 同济大学的校友邮箱需要两个信息： 1.学工号  2.身份证号 </p><p> <img src="https://gitee.com/cit_k/pictures/raw/master/picture/Dgj2K7OYsc6UA8L.png" alt="img"> </p><p>第一步： 搜索学生名单，获取已经毕业了的学生学号  google： 同济大学 学生名单 ，或者直接去同济公开网查  <a href="http://xxgk.tongji.edu.cn/index.php?classid=3148&amp;page=5">http://xxgk.tongji.edu.cn/index.php?classid=3148&amp;page=5</a> </p><p>第二步： 去表格里找 生僻的名字 <img src="https://gitee.com/cit_k/pictures/raw/master/picture/RY9xaQkBq6zeHt7.png" alt="img"> 第三步：上TG去 @sgk123bot 搜索生僻的名字， 多试几个 ，有免费条数，精髓在于只搜索不查看的话 不消耗条数</p><p>  <img src="https://gitee.com/cit_k/pictures/raw/master/picture/SCpGQFNVdqXyack.png" alt="img"> </p><p>第四步： 找到只有一条记录的，如我找的这个  <img src="https://gitee.com/cit_k/pictures/raw/master/picture/jZC3WFONt9sBTHk.png" alt="img"> </p><p>第五步： 回到校友邮箱，输入他的学工号，你的手机号 进行注册，让你验证身份证就输入他的，搞定。    </p><p>第六步： 拿到邮箱以后github上找 onemanager 这个项目，用heroku搭建列表程序(同济可以用API但不能创建API，onemanager自带同济API，是最简单的) </p><p> 第七步： 搭建完成后配置邮箱时会自动弹窗授权，点击确定后在下面这个图的地方什么都不选，点确认就OK了  <img src="https://gitee.com/cit_k/pictures/raw/master/picture/duwWgDxq42VLXlU.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 白票 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 黑科技 </tag>
            
            <tag> 白票 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gitkarken Pro版本的破解使用</title>
      <link href="2020/12/25/Gitkarken%20Pro%E7%89%88%E6%9C%AC%E7%9A%84%E7%A0%B4%E8%A7%A3%E4%BD%BF%E7%94%A8/"/>
      <url>2020/12/25/Gitkarken%20Pro%E7%89%88%E6%9C%AC%E7%9A%84%E7%A0%B4%E8%A7%A3%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Gitkarken-Pro版本的破解使用"><a href="#Gitkarken-Pro版本的破解使用" class="headerlink" title="Gitkarken Pro版本的破解使用"></a>Gitkarken Pro版本的破解使用</h2><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><ul><li><a href="https://www.gitkraken.com/download">官方地址</a></li><li>历史版本稳定：<a href="https://release.axocdn.com/win64/GitKrakenSetup-6.5.0.exe">GitKraken-6.5.0</a></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/170c816e735f6251" alt="img"></p><h3 id="屏蔽更新host"><a href="#屏蔽更新host" class="headerlink" title="屏蔽更新host"></a>屏蔽更新host</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># gitKraken 更新屏蔽</span><br><span class="line">127.0.0.1 release.gitkraken.com</span><br></pre></td></tr></table></figure><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>需要安装<code>node.js</code>和<code>yarn</code>，其中<code>node.js</code>安装时要选择加入系统环境中，<code>yarn</code>在安装后也要手动进行添加进系统环境。</p><h3 id="打开gitkraken并登陆"><a href="#打开gitkraken并登陆" class="headerlink" title="打开gitkraken并登陆"></a>打开gitkraken并登陆</h3><p>软件右下角有显示版本和Free(功能受限)</p><h3 id="下载破解脚本并破解"><a href="#下载破解脚本并破解" class="headerlink" title="下载破解脚本并破解"></a>下载破解脚本并破解</h3><p>这里使用<a href="https://github.com/5cr1pt/GitCracken">GitCracken</a></p><p>本地clone下载</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/<span class="number">5</span>cr1pt/GitCracken.git</span><br></pre></td></tr></table></figure><p>破解</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> GitCracken/GitCracken</span><br><span class="line">rm yarn.lock</span><br><span class="line">yarn install</span><br><span class="line">yarn build</span><br><span class="line"># 最后一个参数是此程序安装位置下的一个文件</span><br><span class="line"># windows gitbash</span><br><span class="line">node dist/bin/gitcracken.js patcher --asar ~/AppData/Local/gitkraken/app-<span class="number">6</span>.<span class="number">5</span>.<span class="number">0</span>/resources/app.asar</span><br><span class="line"># mac </span><br><span class="line">node dist/bin/gitcracken.js patcher --asar 你的gitkraken的目录/resources/app.asar</span><br></pre></td></tr></table></figure><h3 id="重启gitkraken则能看见右下角的Pro"><a href="#重启gitkraken则能看见右下角的Pro" class="headerlink" title="重启gitkraken则能看见右下角的Pro"></a>重启gitkraken则能看见右下角的Pro</h3><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/170c80eee33fc9c1" alt="img"></p><p>切换账号则重新执行node命令</p><h3 id="破解中遇到的问题"><a href="#破解中遇到的问题" class="headerlink" title="破解中遇到的问题"></a>破解中遇到的问题</h3><ol><li><p>破解最后一步使用的文件参数，若是失败的话改为自己文件的绝对位置</p></li><li><p>安装<code>node.js</code>和<code>yarn</code>之后重启，使用<code>yarn --version</code>验证是否能够使用</p></li><li><p>成功破解之后，是在<code>app.asar</code>做的修改，若是你之前打开了程序并且登录了<code>Github</code>其中保留的有你的信息，所以若是更换账户需要重新破解一次</p></li><li><p>我在最后一步破解之后，打开一直卡在启动界面上，我把<code>app.asar</code>拷贝出来重新安装了一遍，然后替换文件<code>app.asar</code>重新打开，在右下角看到<code>Pro</code>提示，若是显示是<code>Free</code>直接点击应该会变换。</p></li><li><p>在当前（2020.12.25）使用的7.0.1版本仍是可以破解的，但是为了之后保持能用最好不要更新。由于系统图标指向的是<code>Update.exe</code>程序，可在快捷方式中进行修改指向程序的真正位置。另外在<code>hosts</code>中加入<code>127.0.0.1 release.gitkraken.com</code>屏蔽更新。关于此程序的右键功能，在知乎有看大佬提到说需要修改注册表，我是直接将其关闭了</p></li></ol><p>参考文章:</p><ul><li><a href="https://juejin.cn/post/6844904087004135432">gitKraken 6.5.0 免收费破解</a></li><li><a href="https://hbaaa.github.io/2020/07/08/Gitkarken%E7%A0%B4%E8%A7%A3/">Gitkarken破解</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 破解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 破解 </tag>
            
            <tag> 黑科技 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一篇Hexo blog文章——Hexo + Gitee 部署个人博客</title>
      <link href="2020/12/24/%E7%AC%AC%E4%B8%80%E7%AF%87Hexo%20blog%E6%96%87%E7%AB%A0%E2%80%94%E2%80%94Hexo%20+%20Gitee%20%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>2020/12/24/%E7%AC%AC%E4%B8%80%E7%AF%87Hexo%20blog%E6%96%87%E7%AB%A0%E2%80%94%E2%80%94Hexo%20+%20Gitee%20%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="第一篇Hexo-blog文章——Hexo-Gitee-部署个人博客"><a href="#第一篇Hexo-blog文章——Hexo-Gitee-部署个人博客" class="headerlink" title="第一篇Hexo blog文章——Hexo + Gitee 部署个人博客"></a>第一篇Hexo blog文章——Hexo + Gitee 部署个人博客</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>小组的谢老师给我们寒假布置了任务——建博客。害，其实博客这玩意儿，也就是那种“三分钟热度”，这里需要用数据说话：小组的金鼎师哥给我们培训前端展示过自己的博客，印象当中文章大多是生活感言建博之处，文章越往后时间越密集越往前越稀疏啊哈哈哈哈哈哈最后就看不到博客了(也不知是换域名了还是服务器关了)；添昊师哥<a href="https://loner1024.top/">博客</a>底子足初中就开始建了，开了又关关了又开，最近考研文章不高产了[笑哭]，但仍是我等楷模；倩师姐的博客太难见了，我当时从师哥那儿知道博客后就就就看了一眼啊一眼，啪，就没了。。。我，有一种预感，这经历会似曾相识！</p><blockquote><p>2021.1.15更新，今天才知道金鼎师哥原来是博客域名到期了，用的是<a href="http://typecho.org/">typecho</a>搭建的；添昊师哥是部署在github应该双路线在coding上也部署了不然没那么快，jekyll框架+H2O主题；倩师姐也是在github上弄得，机智的我那她的仓库重现一下结果里面没文章[好吧师姐更机智]，但可以看出是Hexo框架，同时也发现了被灰藏多年的公众号哈哈哈哈哈哈</p></blockquote><p>其实我去年就在github建了博客，科学上网的原因速度慢、百度难收录等诟病，然后就没管了。。。放了将近一年该臭了[笑哭]反正是不想再碰了</p><p>目前市场上比较火的一些博客框架： <strong>Hexo、jekyll、Solo、Halo 、gohugo、VuePress、wordpress</strong> 等等 ，这些都是开源的静态博客框架（没有登录注册，后台管理等等）好处就是能够非常快速的搭建好自己的个人博客（也是要一定前端知识的），但是你若是部署到服务器也是需要票子不断维护的Pass！Next！部署到github白票国外服务器又走了老路Pass！那有没有更好的办法呢？</p><p>当然，而且有很多，但我选择了Hexo + Gitee：</p><ul><li>Hexo富含了丰富的主题和扩展包，很大众</li><li>Gitee码云，国内代码托管平台速度快，我很爱国嘿嘿嘿</li></ul><hr><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200250982.png" alt="在这里插入图片描述"></p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p><strong>1、安装 Node.js 环境：</strong> 因为 Hexo 是基于Node.js 的博客框架，就像 Java 要依赖 JDK 环境一样。</p><ul><li>node下载地址：<a href="http://nodejs.cn/download/">http://nodejs.cn/download/</a> ，傻瓜式安装，这里不再详述</li></ul><p><strong>NodeJS环境安装重点拓展：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认node.js安装成功：运行下面两个命令打印版本号即可</span></span><br><span class="line">node -v</span><br><span class="line">npm  -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Node.js 淘宝镜像加速器 （cnpm）</span></span><br><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 node 类库默认安装位置</span></span><br><span class="line"><span class="comment"># 默认是在 C:\Users\lingStudy\AppData\Roaming\npm</span></span><br><span class="line"></span><br><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">&quot;D:\nodejs安装路径\node_global&quot;</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">&quot;D:\nodejs安装路径\node_cache&quot;</span></span><br><span class="line"><span class="comment"># 查看修改是否成功</span></span><br><span class="line">npm root -g</span><br><span class="line"><span class="comment"># 然后把D:\install\node\node_global配置到环境变量的 PATH 下即可</span></span><br></pre></td></tr></table></figure><p><strong>2、安装版本控制工具 Git ：</strong> 用来将本地项目托管到码云，所以还需要自己注册一个码云的账号</p><p>下载地址：<a href="https://git-scm.com/download">https://git-scm.com/download</a> 学程序的，在工作中 Git 是必知必会的，还没学的建议去看看，所以这里不再详细介绍 Git</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Git一些重要配置</span></span><br><span class="line">git config --global user.name <span class="string">&quot;lxxxxdy&quot;</span>  <span class="comment">#码云用户名</span></span><br><span class="line">git config --global user.email <span class="string">&quot;xxx83@qq.com&quot;</span>   <span class="comment">#邮箱</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成SSH公钥并添加到码云，实现免密码登录</span></span><br><span class="line"><span class="comment"># 1、生成公钥</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="comment"># 2、进入 C:\Users\主机名\.ssh 目录，把 id_rsa.pub 里面的信息复制到码云的 SSH公钥 中即可</span></span><br></pre></td></tr></table></figure><p><strong>Hexo 官网：</strong> <a href="https://hexo.io/zh-cn/">https://hexo.io/zh-cn/</a><br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200636724.png" alt="在这里插入图片描述"></p><p><strong>3、Hexo安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全局安装</span></span><br><span class="line">npm install hexo-cli -g</span><br><span class="line"><span class="comment"># 查看hexo版本</span></span><br><span class="line">hexo -v</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200739294.png" alt="在这里插入图片描述"></p><h2 id="创建本地博客站点"><a href="#创建本地博客站点" class="headerlink" title="创建本地博客站点"></a>创建本地博客站点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化一个项目，hexoblog 是项目名</span></span><br><span class="line">hexo init  hexoblog</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200820716.png" alt="在这里插入图片描述"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、进入hexoblog项目目录</span></span><br><span class="line"><span class="built_in">cd</span> hexoblog</span><br><span class="line"><span class="comment">#/2、安装 hexoblog 项目的依赖包</span></span><br><span class="line">npm install</span><br><span class="line"><span class="comment">#/3、启动 hexoblog 项目服务</span></span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200859628.png" alt="在这里插入图片描述"><br>此时，访问 <a href="http://localhost:4000/">http://localhost:4000/</a> 即可看到 hexo 默认的页面和一篇“Hello World”默认生成的文章<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802200937295.png" alt="在这里插入图片描述"><br>至此，Hexo 项目搭建成功！</p><blockquote><p>项目主要文件目录介绍：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── .deploy       <span class="comment"># 需要部署的文件</span></span><br><span class="line">├── node_modules  <span class="comment"># 项目所有的依赖包和插件</span></span><br><span class="line">├── public        <span class="comment"># 生成的静态网页文件</span></span><br><span class="line">├── scaffolds     <span class="comment"># 文章模板</span></span><br><span class="line">├── <span class="built_in">source</span>        <span class="comment"># 博客正文和其他源文件等都应该放在这里</span></span><br><span class="line">|   ├── _drafts   <span class="comment"># 草稿</span></span><br><span class="line">|   └── _posts    <span class="comment"># 文章</span></span><br><span class="line">├── themes        <span class="comment"># 主题</span></span><br><span class="line">├── _config.yml   <span class="comment"># 全局配置文件</span></span><br><span class="line">└── package.json  <span class="comment"># 项目依赖信息</span></span><br></pre></td></tr></table></figure><h2 id="新建一篇blog文章"><a href="#新建一篇blog文章" class="headerlink" title="新建一篇blog文章"></a>新建一篇blog文章</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一篇名为 第一篇Hexo blog文章 的文章</span></span><br><span class="line">hexo new <span class="string">&quot;第一篇Hexo blog文章&quot;</span></span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201048569.png" alt="在这里插入图片描述"><br>  之后，就可以直接编辑刚刚新建的文章，再次启动服务查看效果，如下，这里有一个问题，Hexo框架文章中的图片只支持外链的形式，有很多方法解决，比如，可以在码云或者七牛云部署一个自己的图床。<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201113758.png" alt="在这里插入图片描述"></p><h2 id="将项目部署到码云"><a href="#将项目部署到码云" class="headerlink" title="将项目部署到码云"></a>将项目部署到码云</h2><p>1、在码云新建一个仓库，注意标红的地方，这里我的码云用户名为 <strong>lingstudy</strong><br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201146107.png" alt="在这里插入图片描述"><br>2、在项目根目录下安装git部署插件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 之后就可以使用 hexo deploy（或简写 hexo d）将项目部署到gitee远程仓库</span></span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201219532.png" alt="在这里插入图片描述"><br>3、修改项目配置文件：<strong>_config.yml</strong>，在最下面，修改如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: 仓库URL地址</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/2020080220131539.png" alt="在这里插入图片描述"><br>4、使用命令 <strong>hexo d</strong> 将项目部署到 gitee 远程仓库，此时本地文件夹中出现有一个public文件夹。<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201344312.png" alt="在这里插入图片描述"><br>5、开启 Gitee Pages 静态网页托管服务<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201407831.png" alt="在这里插入图片描述"><br>之后使用提供的网址即可访问博客，每次重新上传代码到gitee时，都需要点击下图的更新按钮<strong>重启page服务</strong><br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/202008022014338.png" alt="在这里插入图片描述"><br>访问生成的网址 <a href="https://lingstudy.gitee.io/">https://lingstudy.gitee.io/</a> ，部署成功！<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201510794.png" alt="在这里插入图片描述"></p><h2 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h2><p>官网主题：<a href="https://hexo.io/themes/">官方主题</a><br>可以去官网找自己喜欢的主题，下载下来，我这里就随便拿一个来演示了</p><p>1、进入所下载主题根目录下的 theme 目录，将里面的文件复制到自己项目的 theme 目录下<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/2020080220154554.png" alt="在这里插入图片描述"><br>2、修改根目录下的配置文件 <strong>_config.yml</strong><br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201608536.png" alt="在这里插入图片描述"><br>3、启动项目，访问：<a href="http://localhost:4000/">http://localhost:4000/</a> 先在本地查看主题是否修改成功<br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201649173.png" alt="在这里插入图片描述"><br>4、将修改后的项目部署到远程仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成静态网站文件</span></span><br><span class="line">hexo g  </span><br><span class="line"><span class="comment"># 上传到远程仓库</span></span><br><span class="line">hexo d  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、清除 hexo 的缓存</span></span><br><span class="line">hexo clean</span><br><span class="line"><span class="comment"># 2、采用一键部署</span></span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201726963.png" alt="在这里插入图片描述"><br>5、访问 <a href="https://lingstudy.gitee.io/">https://lingstudy.gitee.io/</a> 主题样式修改并部署成功！</p><p><strong>（这里若出现样式错乱，可能是浏览器缓存问题，执行 Ctrl + F5 强制刷新一下即可）</strong><br><img src="https://gitee.com/cit_k/pictures/raw/master/picture/20200802201812780.png" alt="在这里插入图片描述"><br>至此，Hexo + Gitee 部署自己的个人博客完成！</p><h2 id="拓展：快速编写文章"><a href="#拓展：快速编写文章" class="headerlink" title="拓展：快速编写文章"></a>拓展：快速编写文章</h2><p>新建文章时每次都要执行 <strong>hexo new “blogName”</strong> 命令很麻烦</p><p>可以直接到根目录 /source/_posts 目录下，创建一个.md 文件进行编写，在文件的顶部添加下面内容就可以了，主要写一个 title 就好了，其他都可以省略</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 文章名称</span><br><span class="line">date: 2020-07-30 16:46:07(创建时间)</span><br><span class="line">tags: 标签名</span><br><span class="line">categories: 分类</span><br><span class="line">description: 描述</span><br><span class="line">comments: 是否开启评论(<span class="literal">true</span> or <span class="literal">false</span>)</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>之后，使用 <strong>hexo g –d</strong> 命令推送到 gitee上，并在 gitee 上更新一下 Gitee Pages 服务即可</p><hr><h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2><p>步骤不是太复杂，思路清晰就行，但不得不说还是麻烦，特别是主题的选择配置要花费非常多的时间（强迫症的就更多了）<br>我的博客，可能，要重走师哥师姐博客的路了。。。也许，师弟师妹也是</p><p>参考文章：</p><ul><li><a href="https://blog.csdn.net/weixin_42365530/article/details/107750003">Hexo+gitee：30分钟搭建一个自己的个人博客网站</a></li><li><a href="https://butterfly.js.org/posts/21cfbf15/">Butterfly 安装文档(一) 快速开始</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
